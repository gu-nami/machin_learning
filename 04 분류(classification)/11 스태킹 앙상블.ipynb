{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec01a1f",
   "metadata": {},
   "source": [
    "## 11 스태킹 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa144695",
   "metadata": {},
   "source": [
    "스태킹(Stacking)은 개별적인 여러 알고리즘을 서로 결합해 예측 결과를 도출한다는 점에서 앞에 소개한 배깅(Bagging) 및 부스팅(Boosting)과 공통점을 가지고 있다. 하지만 가장 큰 차이점은 개별 알고리즘으로 예측한 데이터를 기반으로 다시 예측을 수행한다는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a29172",
   "metadata": {},
   "source": [
    "개별 알고리즘의 예측 결과 데이터 세트를 최종적인 메타 데이터 세트로 만들어 별도의 ML 알고리즘으로 최종학습을 수행하고 테스트 데이터를 기반으로 다시 최종 예측을 수행하는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a8366",
   "metadata": {},
   "source": [
    "스태킹 모델은 두 종류의 모델이 필요하다. 첫 번째는 개별적인 기반 모델이고, 두 번째 이 개별 기반 모델의 예측 데이터를 학습 데이터로 만들어서 학습하는 최종 메타 모델이다. 스태킹 모델의 핵심은 여러 개별 모델의 예측 데이터를 각각 스태킹 형태로 결합해 최종 메타 모델의 학습용 피처 데이터 세트와 테스트용 피처 데이터 세트를 만드는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7421fb6f",
   "metadata": {},
   "source": [
    "스태킹을 현실 모델에 적용하는 경우는 그렇게 많지 않지만 캐글과 같은 대회에서 높은 순위를 차지하기 위해 조금이라도 성능 수치를 높여야 할 경우 자주 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099358d",
   "metadata": {},
   "source": [
    "![스태킹](https://velog.velcdn.com/images%2Fsset2323%2Fpost%2Ff0ea0223-4e61-4476-9429-d3c3fabf8415%2Fimage.png)\n",
    "\n",
    "스태킹 모델 개념의 간단한 다이어그램은 위의 그림과 같다. 여러 개의 모델에 대한 예측값을 합한 후, 즉 스태킹 형태로 쌓은 뒤 이에 대한 예측을 다시 수행하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fac81e4",
   "metadata": {},
   "source": [
    "M개의 로우, N개의 피처(칼럼)를 가진 데이터 세트에 스태킹 앙상블을 적용한다고 가정한다. 그리고 학습에 사용할 ML 알고리즘 모델은 모두 3개이다. 먼저 모델별로 각각 학습을 시킨뒤 예측을 수행하면 각각 M개의 로우를 가진 1개의 레이블 값을 도출할 것이다. 모델별로 도출된 예측 레이블 값을 다시 합해서(스태킹) 새로운 데이터 세트를 만들고 이렇게 스태킹된 데이터 세트에 대해 최종 모델을 적용해 최종 예측을 하는 것이 스태킹 앙상블 모델이다.\n",
    "\n",
    "![스태킹](https://s1.md5.ltd/image/71c482c59cc125605ab153b894a14826.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b10c53",
   "metadata": {},
   "source": [
    "### 기본 스태킹 모델\n",
    "\n",
    "기본 스태킹 모델을 위스콘신 암 데이터 세트에 적용한다. 데이터를 로딩하고 학습 데이터 세트와 테스트 데이터 세트로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cd8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X_data , y_label , test_size=0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bef9f6",
   "metadata": {},
   "source": [
    "스태킹에 사용될 머신러닝 알고리즘 클래스를 생성한다. 개별 모델은 KNN, 랜덤포레스트, 결정 트리, 에이다부스트이며, 이들 모델의 예측 결과를 합한 데이터 세트로 학습/예측하는 최종 모델은 로지스틱 회귀이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d814588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개별 ML 모델을 위한 Classifier 생성.\n",
    "knn_clf  = KNeighborsClassifier(n_neighbors=4)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# 최종 Stacking 모델을 위한 Classifier생성. \n",
    "lr_final = LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850ad55",
   "metadata": {},
   "source": [
    "개별 모델을 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541bf840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 개별 모델들을 학습. \n",
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "dt_clf.fit(X_train , y_train)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0847b1d",
   "metadata": {},
   "source": [
    "개별 모델의 예측 데이터 세트를 반환하고 각 모델의 예측 정확도를 살펴본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696a3c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 정확도: 0.9211\n",
      "랜덤 포레스트 정확도: 0.9649\n",
      "결정 트리 정확도: 0.9123\n",
      "에이다부스트 정확도: 0.9561 :\n"
     ]
    }
   ],
   "source": [
    "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. \n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "\n",
    "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
    "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "print('에이다부스트 정확도: {0:.4f} :'.format(accuracy_score(y_test, ada_pred)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aaf864c",
   "metadata": {},
   "source": [
    "개별 알고리즘으로부터 예측된 예측값을 칼럼 레벨로 옆으로 붙여서 피처 값으로 만들어, 최종 메타 모델인 로지스틱 회귀에서 학습 데이터로 다시 사용한다. 변환된 예측 데이터세트는 1차원 형태의 ndarray이므로 먼저 반환된 예측 결과를 행 형태로 붙인 뒤, 넘파이의 transpose()를 이용해 행과 열 위치를 바꾼 ndarray로 변환하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedd3d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n",
      "(114, 4)\n"
     ]
    }
   ],
   "source": [
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)\n",
    "\n",
    "# transpose를 이용해 행과 열의 위치 교환. 컬럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦. \n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e270a",
   "metadata": {},
   "source": [
    "예측 데이터로 생성된 데이터 세트를 기반으로 최종 메타 모델인 로지스틱 회귀를 학습하고 예측 정확도를 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f0f3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9649\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(pred, y_test)\n",
    "final = lr_final.predict(pred)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test , final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b509b",
   "metadata": {},
   "source": [
    "이제가지 기본 스태킹 모델의 구성과 적용을 알아보았다. 이번에는 과적합을 개선하기 위한 CV 세트 기반의 스태킹 모델을 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea5279",
   "metadata": {},
   "source": [
    "### CV 세트 기반의 스태킹\n",
    "\n",
    "CV 세트 기반의 스태킹 모델은 과적합을 개선하기 위해 최종 메타 모델을 위한 데이터 세트를 만들 때 교차 검증 기반으로 예측된 결과 데이터 세트를 이용한다. 앞 예제에서 마지막에 메타 모델인 로지스틱 회귀 모델 기반에서 최종 학습할 때 레이블 데이터 세트로 학습 데이터가 아닌 테스트용 레이블 데이터 세트를 기반으로 학습했기에 과적합 문제가 발생할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe4785",
   "metadata": {},
   "source": [
    "CV 세트 기반의 스태킹은 이에 대한 개선을 위해 개별 모델들이 각각 교차 검증으로 메타 모델을 위한 학습용 스태킹 데이터 생성과 예측을 위한 테스트용 스태킹 데이터를 생성한 뒤 이를 기반으로 메타 모델이 학습과 예측을 수행한다. 이는 2단계의 스텝으로 구분될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310e7a2",
   "metadata": {},
   "source": [
    "+ 스텝 1 : 각 모델별로 원본 학습/테스트 데이터를 예측한 결과 값을 기반으로 메타 모델을 위한 학습용/테스트용 데이터를 생성한다.\n",
    "\n",
    "+ 스텝 2 : 스텝 1에서 개별 모델들이 생성한 학습용 데이터를 모두 스태킹 형태로 합쳐서 메타 모델이 학습할 최종 학습용 데이터 세트를 생성한다. 마찬가지로 각 모델들이 생성한 테스트용 데이터를 모두 스태킹 형태로 합쳐서 메타 모델이 예측할 최종 테스트 데이터 세트를 생성한다. 메타 모델은 최종적으로 생성된 학습데이터 세트와 원본 학습 데이터의 레이블 데이터를 기반으로 학습한 뒤, 최종적으로 생성된 테스트 데이터 세트를 예측하고, 원본 테스트 데이터의 레이블 데이터를 기반으로 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc241c3",
   "metadata": {},
   "source": [
    "핵심은 개별 모델에서 메타 모델인 2차 모델에서 사용될 학습용 데이터와 테스트용 데이터를 교차 검증을 통해서 생성하는 것이다. 스텝 1은 개별 모델 레벨에서 수행하는 것이며, 이러한 로직은 여러 개의 개별 모델에서 동일하게 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2599301e",
   "metadata": {},
   "source": [
    "1. 각 모델별로 원본 학습/테스트 데이터를 예측한 결과 값을 기반으로 메타 모델을 위한 학습용/테스트용 데이터를 생성한다.\n",
    "\n",
    "    1) 학습용 데이터를 N개의 Fold로 나누고, N-1개의 Fold는 학습을, 나머지 1개의 Fold는 검증을 위해 사용한다.\n",
    "    \n",
    "    2) N-1개의 Fold로 학습된 개별 모델은 검증용 Fold로 예측을 수행하고 그 결과를 저장한다. 이러한 로직을 N번 반복하면서 검증 Fold를 변경하여 예측 결과를 저장한다. 이렇게 만들어진 예측 결과값들을 메타 모델의 학습 데이터로 사용한다.\n",
    "    \n",
    "    3) 그리고 N번 반복할 때마다 원본 테스트 데이터를 예측하여 이 결과값도 저장하면서 N번의 반복이 끝나면 테스트 데이터의 결과값들의 평균값을 메타 모델의 테스트 데이터로 사용한다.\n",
    "\n",
    "\n",
    "2. 스텝 1에서 개별 모델들이 생성한 학습용 데이터를 모두 스태킹 형태로 합쳐서 메타 모델이 학습할 최종 학습용 데이터세트를 생성한다. 마찬가지로 각 모델들이 생성한 테스트용 데이터를 모두 스태킹 형태로 합쳐서 메타 모델이 예측할 최종 테스트 데이터세트를 생성한다. 메타 모델은 최종적으로 생성된 학습 데이터세트와 원본 학습 데이터의 레이블 데이터를 기반으로 학습한 뒤, 최종적으로 생성된 테스트 데이터세트을 예측하고, 원본 테스트 데이터의 레이블 데이터를 기반으로 평가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a92c9",
   "metadata": {},
   "source": [
    "먼저 1번을 코드로 구현한다. 개별 모델이 메타 모델을 위한 학습용 데이터와 테스트 데이터를 생성하는 것이다. 먼저 get_stacking_base_datasets() 함수를 생성한다. 이 함수에서 개별 모델의 Classifier 객체, 원본인 학습용 피처 데이터, 원본인 학습용 레이블 데이터, 원본인 테스트 피처 데이터, 그리고 K 폴드를 몇 개로 할지를 파라미터로 입력받는다. 함수 내 에서는 폴드의 개수만큼 반복을 수행하면서 폴드된 학습용 데이터로 학습한 뒤 예측 결괏값을 기반으로 메타 모델을 위한 학습용 데이터와 테스트용 데이터를 새롭게 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7c3c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
    "    # 지정된 n_folds값으로 KFold 생성.\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    print(model.__class__.__name__ , ' model 시작 ')\n",
    "    \n",
    "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
    "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
    "        X_tr = X_train_n[train_index] \n",
    "        y_tr = y_train_n[train_index] \n",
    "        X_te = X_train_n[valid_index]  \n",
    "        \n",
    "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
    "        model.fit(X_tr , y_tr)       \n",
    "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
    "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
    "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
    "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
    "            \n",
    "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
    "    \n",
    "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
    "    return train_fold_pred , test_pred_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf3f6d",
   "metadata": {},
   "source": [
    "여러 개의 분류 모델별로 stack_base_model() 함수를 수행한다. 개별 모델은 앞의 기본 스태킹 모델에서 생성한 KNN, 랜덤 포레스트, 에이다부스트 모델이며, 이들 모델별로 get_stacking_base_datasets() 함수를 호출해 각각 메타 모델이 추후에 사용할 학습용, 테스트용 데이터 세트를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0387341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "RandomForestClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "DecisionTreeClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n",
      "AdaBoostClassifier  model 시작 \n",
      "\t 폴드 세트:  0  시작 \n",
      "\t 폴드 세트:  1  시작 \n",
      "\t 폴드 세트:  2  시작 \n",
      "\t 폴드 세트:  3  시작 \n",
      "\t 폴드 세트:  4  시작 \n",
      "\t 폴드 세트:  5  시작 \n",
      "\t 폴드 세트:  6  시작 \n"
     ]
    }
   ],
   "source": [
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,  7)    \n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c82109f",
   "metadata": {},
   "source": [
    "이제 2번을 코드로 구현해본다. 앞의 예제에서 get_stacking_base_datasets() 호출로 반환된 각 모델별 학습 데이터와 테스트 데이터를 합치기만 하면 된다. 넘파이의 concatenate()를 이용해 쉽게 이와 같은 기능을 수행한다. concatenate()는 여러 개의 넘파이의 배열을 칼럼 또는 로우 레벨로 합쳐주는 기능을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c967c669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 Shape: (455, 30) 원본 테스트 피처 Shape: (114, 30)\n",
      "스태킹 학습 피처 데이터 Shape: (455, 4) 스태킹 테스트 피처 데이터 Shape: (114, 4)\n"
     ]
    }
   ],
   "source": [
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)\n",
    "print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,\n",
    "      '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c044f0",
   "metadata": {},
   "source": [
    "이렇게 만들어진 Stack_final_X_train은 메타 모델이 학습할 학습용 피처 데이터 세트이다. 그리고 Stack_final_X_test는 메타 모델이 예측할 테스트용 피처 데이터 세트이다. 스태킹 학습 피처 데이터는 원본 학습 피처 데이터와 로우 크기는 같으며, 4개의 개별 모델 예측값을 합친 것으로 칼럼 크기는 4이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239333f",
   "metadata": {},
   "source": [
    "최종 메타 모델인 로지스틱 회귀를 스태킹된 학습용 피처 데이터 세트와 원본 학습 레이블 데이터로 학습한 후에 스태킹된 테스트 데이터 세트로 예측하고, 예측 결과를 원본 테스트 레이블 데이터와 비교해 정확도를 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3673af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타 모델의 예측 정확도: 0.9737\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)\n",
    "\n",
    "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, stack_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1f45d",
   "metadata": {},
   "source": [
    "지금까지는 개별 모델의 알고리즘에서 파라미터 튜닝을 최적으로 하지 않았지만, 스태킹을 이루는 모델은 최적으로 파라미터를 튜닝한 상태에서 스태킹 모델을 만드는 것이 일반적이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb20ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
