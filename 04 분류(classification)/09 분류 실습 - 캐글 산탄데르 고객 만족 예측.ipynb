{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015c72a3",
   "metadata": {},
   "source": [
    "## 09 분류 실습 - 캐글 산탄데르 고객 만족 예측\n",
    "\n",
    "클래스 레이블 명은 TARGET이며, 이 값이 1이면 불만을 가진 고객, 0이면 만족한 고객이다. 모델의 성능 평가 ROC_AUC(ROC 곡선 영역)로 평가한다. 대부분이 만족이고 불만족인 데이터는 일부일 것이기 때문에 정확도 수치보다는 ROC-AUC가 더 적합하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fe65d9",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a629b84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cust_df = pd.read_csv(\"./train.csv\", encoding='latin-1')\n",
    "print('dataset shape:', cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4700b02",
   "metadata": {},
   "source": [
    "info() 메소드로 피처의 타입과 Null 값 조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4f36c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a11dda5",
   "metadata": {},
   "source": [
    "전체 데이터에서 만족과 불만족의 비율 조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31df3a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    73012\n",
      "1     3008\n",
      "Name: TARGET, dtype: int64\n",
      "unsatisfied 비율은 0.04\n"
     ]
    }
   ],
   "source": [
    "print(cust_df['TARGET'].value_counts())\n",
    "unsatisfied_cnt = cust_df[cust_df['TARGET'] == 1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()\n",
    "print('unsatisfied 비율은 {0:.2f}'.format((unsatisfied_cnt / total_cnt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac81909c",
   "metadata": {},
   "source": [
    "describe() 메서드를 이용해 각 피처의 값 분포 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c4b2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a7dae",
   "metadata": {},
   "source": [
    "var3의 값 조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ead31b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2         74165\n",
      " 8           138\n",
      "-999999      116\n",
      " 9           110\n",
      " 3           108\n",
      " 1           105\n",
      " 13           98\n",
      " 7            97\n",
      " 4            86\n",
      " 12           85\n",
      "Name: var3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cust_df.var3.value_counts()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f58c2",
   "metadata": {},
   "source": [
    "var3은 숫자형이고, 다른 값에 비해 -999999는 너무 편차가 심하므로 -999999를 가장 값이 많은 2로 변환한다. ID피처는 단순 식별자 이므로 드랍한다. 그리고 클래스 데이터 세트와 피처 데이터 세트를 분리해 별도의 데이터 세트로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fed078b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피처 데이터 shape:(76020, 369)\n"
     ]
    }
   ],
   "source": [
    "# var3 피처 값 대체 및 ID 피처 드롭\n",
    "cust_df['var3'].replace(-999999, 2, inplace=True)\n",
    "cust_df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# 피처 세트와 레이블 세트분리. 레이블 컬럼은 DataFrame의 맨 마지막에 위치해 컬럼 위치 -1로 분리\n",
    "X_features = cust_df.iloc[:, :-1]\n",
    "y_labels = cust_df.iloc[:, -1]\n",
    "print('피처 데이터 shape:{0}'.format(X_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d86c0b",
   "metadata": {},
   "source": [
    "학습 데이터 세트와 테스트 데이터 세트로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "772a9673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 Shape:(60816, 369), 테스트 세트 Shape:(15204, 369)\n",
      " 학습 세트 레이블 값 분포 비율\n",
      "0    0.960964\n",
      "1    0.039036\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      " 테스트 세트 레이블 값 분포 비율\n",
      "0    0.9583\n",
      "1    0.0417\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape , X_test.shape))\n",
    "\n",
    "# 비대칭한 데이터 세트이므로 클래스인 Target 값 분포도가 \n",
    "#학습 데이터와 테스트 데이터 세트에 모두 비슷하게 추출 됐는지 확인\n",
    "print(' 학습 세트 레이블 값 분포 비율')\n",
    "print(y_train.value_counts()/train_cnt)\n",
    "print('\\n 테스트 세트 레이블 값 분포 비율')\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ae8efc",
   "metadata": {},
   "source": [
    "XGBoost의 조기 중단(early stopping)의 검증 데이터 세트로 사용하기 위해서 X_train, y_train을 다시 쪼개서 학습과 검증 데이터 세트로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bce1cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train을 다시 학습과 검증 데이터 세트로 분리. \n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train,\n",
    "                                                    test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f280d",
   "metadata": {},
   "source": [
    "### XGBoost 모델 학습과 하이퍼 파라미터 튜닝\n",
    "\n",
    "XGBoost의 학습 모델을 생성하고 예측 결과를 ROC AUC로 평가하기\n",
    "\n",
    "사이킷런 래퍼인 XGBClassifier를 기반으로 학습을 수행한다. 성능 평가 기준이 ROC-AUC이므로 XGBClassifier의 eval_metric은 'auc'로 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ab0848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.82179\tvalidation_1-auc:0.80068\n",
      "[1]\tvalidation_0-auc:0.83092\tvalidation_1-auc:0.80941\n",
      "[2]\tvalidation_0-auc:0.83207\tvalidation_1-auc:0.80903\n",
      "[3]\tvalidation_0-auc:0.83288\tvalidation_1-auc:0.80889\n",
      "[4]\tvalidation_0-auc:0.83414\tvalidation_1-auc:0.80924\n",
      "[5]\tvalidation_0-auc:0.83524\tvalidation_1-auc:0.80907\n",
      "[6]\tvalidation_0-auc:0.83568\tvalidation_1-auc:0.81005\n",
      "[7]\tvalidation_0-auc:0.83741\tvalidation_1-auc:0.81088\n",
      "[8]\tvalidation_0-auc:0.83896\tvalidation_1-auc:0.81305\n",
      "[9]\tvalidation_0-auc:0.83949\tvalidation_1-auc:0.81363\n",
      "[10]\tvalidation_0-auc:0.83908\tvalidation_1-auc:0.81277\n",
      "[11]\tvalidation_0-auc:0.83913\tvalidation_1-auc:0.81260\n",
      "[12]\tvalidation_0-auc:0.84009\tvalidation_1-auc:0.81325\n",
      "[13]\tvalidation_0-auc:0.84081\tvalidation_1-auc:0.81329\n",
      "[14]\tvalidation_0-auc:0.84196\tvalidation_1-auc:0.81380\n",
      "[15]\tvalidation_0-auc:0.84394\tvalidation_1-auc:0.81540\n",
      "[16]\tvalidation_0-auc:0.84414\tvalidation_1-auc:0.81573\n",
      "[17]\tvalidation_0-auc:0.84437\tvalidation_1-auc:0.81577\n",
      "[18]\tvalidation_0-auc:0.84468\tvalidation_1-auc:0.81569\n",
      "[19]\tvalidation_0-auc:0.84586\tvalidation_1-auc:0.81625\n",
      "[20]\tvalidation_0-auc:0.84641\tvalidation_1-auc:0.81619\n",
      "[21]\tvalidation_0-auc:0.84685\tvalidation_1-auc:0.81611\n",
      "[22]\tvalidation_0-auc:0.84735\tvalidation_1-auc:0.81671\n",
      "[23]\tvalidation_0-auc:0.84793\tvalidation_1-auc:0.81682\n",
      "[24]\tvalidation_0-auc:0.84825\tvalidation_1-auc:0.81675\n",
      "[25]\tvalidation_0-auc:0.84893\tvalidation_1-auc:0.81647\n",
      "[26]\tvalidation_0-auc:0.85104\tvalidation_1-auc:0.81724\n",
      "[27]\tvalidation_0-auc:0.85206\tvalidation_1-auc:0.81764\n",
      "[28]\tvalidation_0-auc:0.85327\tvalidation_1-auc:0.81873\n",
      "[29]\tvalidation_0-auc:0.85425\tvalidation_1-auc:0.82038\n",
      "[30]\tvalidation_0-auc:0.85624\tvalidation_1-auc:0.82231\n",
      "[31]\tvalidation_0-auc:0.85716\tvalidation_1-auc:0.82223\n",
      "[32]\tvalidation_0-auc:0.85785\tvalidation_1-auc:0.82261\n",
      "[33]\tvalidation_0-auc:0.85878\tvalidation_1-auc:0.82289\n",
      "[34]\tvalidation_0-auc:0.85931\tvalidation_1-auc:0.82389\n",
      "[35]\tvalidation_0-auc:0.86006\tvalidation_1-auc:0.82446\n",
      "[36]\tvalidation_0-auc:0.86079\tvalidation_1-auc:0.82537\n",
      "[37]\tvalidation_0-auc:0.86101\tvalidation_1-auc:0.82546\n",
      "[38]\tvalidation_0-auc:0.86156\tvalidation_1-auc:0.82593\n",
      "[39]\tvalidation_0-auc:0.86224\tvalidation_1-auc:0.82610\n",
      "[40]\tvalidation_0-auc:0.86284\tvalidation_1-auc:0.82603\n",
      "[41]\tvalidation_0-auc:0.86314\tvalidation_1-auc:0.82624\n",
      "[42]\tvalidation_0-auc:0.86388\tvalidation_1-auc:0.82694\n",
      "[43]\tvalidation_0-auc:0.86493\tvalidation_1-auc:0.82741\n",
      "[44]\tvalidation_0-auc:0.86557\tvalidation_1-auc:0.82757\n",
      "[45]\tvalidation_0-auc:0.86643\tvalidation_1-auc:0.82795\n",
      "[46]\tvalidation_0-auc:0.86733\tvalidation_1-auc:0.82860\n",
      "[47]\tvalidation_0-auc:0.86788\tvalidation_1-auc:0.82878\n",
      "[48]\tvalidation_0-auc:0.86815\tvalidation_1-auc:0.82881\n",
      "[49]\tvalidation_0-auc:0.86902\tvalidation_1-auc:0.83000\n",
      "[50]\tvalidation_0-auc:0.86956\tvalidation_1-auc:0.83040\n",
      "[51]\tvalidation_0-auc:0.86992\tvalidation_1-auc:0.83036\n",
      "[52]\tvalidation_0-auc:0.87037\tvalidation_1-auc:0.83061\n",
      "[53]\tvalidation_0-auc:0.87088\tvalidation_1-auc:0.83071\n",
      "[54]\tvalidation_0-auc:0.87157\tvalidation_1-auc:0.83092\n",
      "[55]\tvalidation_0-auc:0.87206\tvalidation_1-auc:0.83143\n",
      "[56]\tvalidation_0-auc:0.87277\tvalidation_1-auc:0.83170\n",
      "[57]\tvalidation_0-auc:0.87329\tvalidation_1-auc:0.83171\n",
      "[58]\tvalidation_0-auc:0.87369\tvalidation_1-auc:0.83168\n",
      "[59]\tvalidation_0-auc:0.87428\tvalidation_1-auc:0.83172\n",
      "[60]\tvalidation_0-auc:0.87489\tvalidation_1-auc:0.83166\n",
      "[61]\tvalidation_0-auc:0.87565\tvalidation_1-auc:0.83160\n",
      "[62]\tvalidation_0-auc:0.87618\tvalidation_1-auc:0.83164\n",
      "[63]\tvalidation_0-auc:0.87685\tvalidation_1-auc:0.83174\n",
      "[64]\tvalidation_0-auc:0.87749\tvalidation_1-auc:0.83209\n",
      "[65]\tvalidation_0-auc:0.87810\tvalidation_1-auc:0.83233\n",
      "[66]\tvalidation_0-auc:0.87867\tvalidation_1-auc:0.83246\n",
      "[67]\tvalidation_0-auc:0.87932\tvalidation_1-auc:0.83256\n",
      "[68]\tvalidation_0-auc:0.87982\tvalidation_1-auc:0.83264\n",
      "[69]\tvalidation_0-auc:0.88036\tvalidation_1-auc:0.83250\n",
      "[70]\tvalidation_0-auc:0.88087\tvalidation_1-auc:0.83226\n",
      "[71]\tvalidation_0-auc:0.88182\tvalidation_1-auc:0.83208\n",
      "[72]\tvalidation_0-auc:0.88232\tvalidation_1-auc:0.83234\n",
      "[73]\tvalidation_0-auc:0.88293\tvalidation_1-auc:0.83247\n",
      "[74]\tvalidation_0-auc:0.88342\tvalidation_1-auc:0.83244\n",
      "[75]\tvalidation_0-auc:0.88401\tvalidation_1-auc:0.83246\n",
      "[76]\tvalidation_0-auc:0.88451\tvalidation_1-auc:0.83238\n",
      "[77]\tvalidation_0-auc:0.88487\tvalidation_1-auc:0.83224\n",
      "[78]\tvalidation_0-auc:0.88518\tvalidation_1-auc:0.83234\n",
      "[79]\tvalidation_0-auc:0.88561\tvalidation_1-auc:0.83233\n",
      "[80]\tvalidation_0-auc:0.88637\tvalidation_1-auc:0.83253\n",
      "[81]\tvalidation_0-auc:0.88665\tvalidation_1-auc:0.83255\n",
      "[82]\tvalidation_0-auc:0.88703\tvalidation_1-auc:0.83245\n",
      "[83]\tvalidation_0-auc:0.88756\tvalidation_1-auc:0.83261\n",
      "[84]\tvalidation_0-auc:0.88791\tvalidation_1-auc:0.83249\n",
      "[85]\tvalidation_0-auc:0.88852\tvalidation_1-auc:0.83263\n",
      "[86]\tvalidation_0-auc:0.88895\tvalidation_1-auc:0.83251\n",
      "[87]\tvalidation_0-auc:0.88933\tvalidation_1-auc:0.83237\n",
      "[88]\tvalidation_0-auc:0.88970\tvalidation_1-auc:0.83233\n",
      "[89]\tvalidation_0-auc:0.89021\tvalidation_1-auc:0.83231\n",
      "[90]\tvalidation_0-auc:0.89065\tvalidation_1-auc:0.83222\n",
      "[91]\tvalidation_0-auc:0.89105\tvalidation_1-auc:0.83236\n",
      "[92]\tvalidation_0-auc:0.89142\tvalidation_1-auc:0.83218\n",
      "[93]\tvalidation_0-auc:0.89176\tvalidation_1-auc:0.83239\n",
      "[94]\tvalidation_0-auc:0.89213\tvalidation_1-auc:0.83220\n",
      "[95]\tvalidation_0-auc:0.89241\tvalidation_1-auc:0.83227\n",
      "[96]\tvalidation_0-auc:0.89278\tvalidation_1-auc:0.83213\n",
      "[97]\tvalidation_0-auc:0.89302\tvalidation_1-auc:0.83223\n",
      "[98]\tvalidation_0-auc:0.89329\tvalidation_1-auc:0.83209\n",
      "[99]\tvalidation_0-auc:0.89361\tvalidation_1-auc:0.83227\n",
      "[100]\tvalidation_0-auc:0.89380\tvalidation_1-auc:0.83236\n",
      "[101]\tvalidation_0-auc:0.89410\tvalidation_1-auc:0.83232\n",
      "[102]\tvalidation_0-auc:0.89438\tvalidation_1-auc:0.83227\n",
      "[103]\tvalidation_0-auc:0.89474\tvalidation_1-auc:0.83220\n",
      "[104]\tvalidation_0-auc:0.89509\tvalidation_1-auc:0.83221\n",
      "[105]\tvalidation_0-auc:0.89550\tvalidation_1-auc:0.83226\n",
      "[106]\tvalidation_0-auc:0.89586\tvalidation_1-auc:0.83224\n",
      "[107]\tvalidation_0-auc:0.89604\tvalidation_1-auc:0.83231\n",
      "[108]\tvalidation_0-auc:0.89611\tvalidation_1-auc:0.83229\n",
      "[109]\tvalidation_0-auc:0.89634\tvalidation_1-auc:0.83230\n",
      "[110]\tvalidation_0-auc:0.89666\tvalidation_1-auc:0.83242\n",
      "[111]\tvalidation_0-auc:0.89677\tvalidation_1-auc:0.83238\n",
      "[112]\tvalidation_0-auc:0.89695\tvalidation_1-auc:0.83241\n",
      "[113]\tvalidation_0-auc:0.89720\tvalidation_1-auc:0.83241\n",
      "[114]\tvalidation_0-auc:0.89728\tvalidation_1-auc:0.83247\n",
      "[115]\tvalidation_0-auc:0.89739\tvalidation_1-auc:0.83249\n",
      "[116]\tvalidation_0-auc:0.89764\tvalidation_1-auc:0.83240\n",
      "[117]\tvalidation_0-auc:0.89780\tvalidation_1-auc:0.83240\n",
      "[118]\tvalidation_0-auc:0.89793\tvalidation_1-auc:0.83257\n",
      "[119]\tvalidation_0-auc:0.89851\tvalidation_1-auc:0.83260\n",
      "[120]\tvalidation_0-auc:0.89886\tvalidation_1-auc:0.83279\n",
      "[121]\tvalidation_0-auc:0.89929\tvalidation_1-auc:0.83272\n",
      "[122]\tvalidation_0-auc:0.89957\tvalidation_1-auc:0.83273\n",
      "[123]\tvalidation_0-auc:0.90005\tvalidation_1-auc:0.83269\n",
      "[124]\tvalidation_0-auc:0.90036\tvalidation_1-auc:0.83284\n",
      "[125]\tvalidation_0-auc:0.90077\tvalidation_1-auc:0.83297\n",
      "[126]\tvalidation_0-auc:0.90086\tvalidation_1-auc:0.83300\n",
      "[127]\tvalidation_0-auc:0.90114\tvalidation_1-auc:0.83315\n",
      "[128]\tvalidation_0-auc:0.90151\tvalidation_1-auc:0.83316\n",
      "[129]\tvalidation_0-auc:0.90181\tvalidation_1-auc:0.83337\n",
      "[130]\tvalidation_0-auc:0.90211\tvalidation_1-auc:0.83340\n",
      "[131]\tvalidation_0-auc:0.90240\tvalidation_1-auc:0.83340\n",
      "[132]\tvalidation_0-auc:0.90266\tvalidation_1-auc:0.83353\n",
      "[133]\tvalidation_0-auc:0.90277\tvalidation_1-auc:0.83347\n",
      "[134]\tvalidation_0-auc:0.90279\tvalidation_1-auc:0.83353\n",
      "[135]\tvalidation_0-auc:0.90292\tvalidation_1-auc:0.83353\n",
      "[136]\tvalidation_0-auc:0.90302\tvalidation_1-auc:0.83344\n",
      "[137]\tvalidation_0-auc:0.90309\tvalidation_1-auc:0.83348\n",
      "[138]\tvalidation_0-auc:0.90312\tvalidation_1-auc:0.83344\n",
      "[139]\tvalidation_0-auc:0.90325\tvalidation_1-auc:0.83340\n",
      "[140]\tvalidation_0-auc:0.90338\tvalidation_1-auc:0.83335\n",
      "[141]\tvalidation_0-auc:0.90339\tvalidation_1-auc:0.83339\n",
      "[142]\tvalidation_0-auc:0.90363\tvalidation_1-auc:0.83351\n",
      "[143]\tvalidation_0-auc:0.90383\tvalidation_1-auc:0.83358\n",
      "[144]\tvalidation_0-auc:0.90395\tvalidation_1-auc:0.83357\n",
      "[145]\tvalidation_0-auc:0.90399\tvalidation_1-auc:0.83361\n",
      "[146]\tvalidation_0-auc:0.90417\tvalidation_1-auc:0.83354\n",
      "[147]\tvalidation_0-auc:0.90430\tvalidation_1-auc:0.83349\n",
      "[148]\tvalidation_0-auc:0.90434\tvalidation_1-auc:0.83346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149]\tvalidation_0-auc:0.90451\tvalidation_1-auc:0.83346\n",
      "[150]\tvalidation_0-auc:0.90459\tvalidation_1-auc:0.83343\n",
      "[151]\tvalidation_0-auc:0.90462\tvalidation_1-auc:0.83344\n",
      "[152]\tvalidation_0-auc:0.90476\tvalidation_1-auc:0.83342\n",
      "[153]\tvalidation_0-auc:0.90494\tvalidation_1-auc:0.83339\n",
      "[154]\tvalidation_0-auc:0.90507\tvalidation_1-auc:0.83336\n",
      "[155]\tvalidation_0-auc:0.90512\tvalidation_1-auc:0.83334\n",
      "[156]\tvalidation_0-auc:0.90518\tvalidation_1-auc:0.83331\n",
      "[157]\tvalidation_0-auc:0.90524\tvalidation_1-auc:0.83339\n",
      "[158]\tvalidation_0-auc:0.90543\tvalidation_1-auc:0.83330\n",
      "[159]\tvalidation_0-auc:0.90553\tvalidation_1-auc:0.83331\n",
      "[160]\tvalidation_0-auc:0.90567\tvalidation_1-auc:0.83342\n",
      "[161]\tvalidation_0-auc:0.90586\tvalidation_1-auc:0.83339\n",
      "[162]\tvalidation_0-auc:0.90592\tvalidation_1-auc:0.83340\n",
      "[163]\tvalidation_0-auc:0.90594\tvalidation_1-auc:0.83340\n",
      "[164]\tvalidation_0-auc:0.90622\tvalidation_1-auc:0.83337\n",
      "[165]\tvalidation_0-auc:0.90634\tvalidation_1-auc:0.83333\n",
      "[166]\tvalidation_0-auc:0.90645\tvalidation_1-auc:0.83329\n",
      "[167]\tvalidation_0-auc:0.90654\tvalidation_1-auc:0.83329\n",
      "[168]\tvalidation_0-auc:0.90659\tvalidation_1-auc:0.83336\n",
      "[169]\tvalidation_0-auc:0.90670\tvalidation_1-auc:0.83339\n",
      "[170]\tvalidation_0-auc:0.90675\tvalidation_1-auc:0.83341\n",
      "[171]\tvalidation_0-auc:0.90679\tvalidation_1-auc:0.83334\n",
      "[172]\tvalidation_0-auc:0.90701\tvalidation_1-auc:0.83321\n",
      "[173]\tvalidation_0-auc:0.90702\tvalidation_1-auc:0.83321\n",
      "[174]\tvalidation_0-auc:0.90706\tvalidation_1-auc:0.83319\n",
      "[175]\tvalidation_0-auc:0.90720\tvalidation_1-auc:0.83323\n",
      "[176]\tvalidation_0-auc:0.90730\tvalidation_1-auc:0.83325\n",
      "[177]\tvalidation_0-auc:0.90741\tvalidation_1-auc:0.83323\n",
      "[178]\tvalidation_0-auc:0.90753\tvalidation_1-auc:0.83318\n",
      "[179]\tvalidation_0-auc:0.90761\tvalidation_1-auc:0.83317\n",
      "[180]\tvalidation_0-auc:0.90768\tvalidation_1-auc:0.83315\n",
      "[181]\tvalidation_0-auc:0.90773\tvalidation_1-auc:0.83313\n",
      "[182]\tvalidation_0-auc:0.90785\tvalidation_1-auc:0.83312\n",
      "[183]\tvalidation_0-auc:0.90804\tvalidation_1-auc:0.83303\n",
      "[184]\tvalidation_0-auc:0.90816\tvalidation_1-auc:0.83305\n",
      "[185]\tvalidation_0-auc:0.90821\tvalidation_1-auc:0.83307\n",
      "[186]\tvalidation_0-auc:0.90823\tvalidation_1-auc:0.83307\n",
      "[187]\tvalidation_0-auc:0.90836\tvalidation_1-auc:0.83308\n",
      "[188]\tvalidation_0-auc:0.90841\tvalidation_1-auc:0.83309\n",
      "[189]\tvalidation_0-auc:0.90882\tvalidation_1-auc:0.83304\n",
      "[190]\tvalidation_0-auc:0.90885\tvalidation_1-auc:0.83306\n",
      "[191]\tvalidation_0-auc:0.90897\tvalidation_1-auc:0.83301\n",
      "[192]\tvalidation_0-auc:0.90909\tvalidation_1-auc:0.83302\n",
      "[193]\tvalidation_0-auc:0.90914\tvalidation_1-auc:0.83303\n",
      "[194]\tvalidation_0-auc:0.90927\tvalidation_1-auc:0.83300\n",
      "[195]\tvalidation_0-auc:0.90946\tvalidation_1-auc:0.83298\n",
      "[196]\tvalidation_0-auc:0.90959\tvalidation_1-auc:0.83291\n",
      "[197]\tvalidation_0-auc:0.90970\tvalidation_1-auc:0.83293\n",
      "[198]\tvalidation_0-auc:0.90972\tvalidation_1-auc:0.83293\n",
      "[199]\tvalidation_0-auc:0.90986\tvalidation_1-auc:0.83293\n",
      "[200]\tvalidation_0-auc:0.90992\tvalidation_1-auc:0.83293\n",
      "[201]\tvalidation_0-auc:0.90997\tvalidation_1-auc:0.83291\n",
      "[202]\tvalidation_0-auc:0.91010\tvalidation_1-auc:0.83290\n",
      "[203]\tvalidation_0-auc:0.91016\tvalidation_1-auc:0.83287\n",
      "[204]\tvalidation_0-auc:0.91025\tvalidation_1-auc:0.83289\n",
      "[205]\tvalidation_0-auc:0.91045\tvalidation_1-auc:0.83282\n",
      "[206]\tvalidation_0-auc:0.91056\tvalidation_1-auc:0.83280\n",
      "[207]\tvalidation_0-auc:0.91060\tvalidation_1-auc:0.83287\n",
      "[208]\tvalidation_0-auc:0.91063\tvalidation_1-auc:0.83291\n",
      "[209]\tvalidation_0-auc:0.91068\tvalidation_1-auc:0.83292\n",
      "[210]\tvalidation_0-auc:0.91069\tvalidation_1-auc:0.83290\n",
      "[211]\tvalidation_0-auc:0.91077\tvalidation_1-auc:0.83286\n",
      "[212]\tvalidation_0-auc:0.91084\tvalidation_1-auc:0.83286\n",
      "[213]\tvalidation_0-auc:0.91099\tvalidation_1-auc:0.83293\n",
      "[214]\tvalidation_0-auc:0.91133\tvalidation_1-auc:0.83279\n",
      "[215]\tvalidation_0-auc:0.91137\tvalidation_1-auc:0.83276\n",
      "[216]\tvalidation_0-auc:0.91143\tvalidation_1-auc:0.83274\n",
      "[217]\tvalidation_0-auc:0.91150\tvalidation_1-auc:0.83274\n",
      "[218]\tvalidation_0-auc:0.91158\tvalidation_1-auc:0.83268\n",
      "[219]\tvalidation_0-auc:0.91163\tvalidation_1-auc:0.83267\n",
      "[220]\tvalidation_0-auc:0.91165\tvalidation_1-auc:0.83267\n",
      "[221]\tvalidation_0-auc:0.91175\tvalidation_1-auc:0.83269\n",
      "[222]\tvalidation_0-auc:0.91192\tvalidation_1-auc:0.83259\n",
      "[223]\tvalidation_0-auc:0.91194\tvalidation_1-auc:0.83260\n",
      "[224]\tvalidation_0-auc:0.91199\tvalidation_1-auc:0.83258\n",
      "[225]\tvalidation_0-auc:0.91206\tvalidation_1-auc:0.83262\n",
      "[226]\tvalidation_0-auc:0.91210\tvalidation_1-auc:0.83262\n",
      "[227]\tvalidation_0-auc:0.91215\tvalidation_1-auc:0.83263\n",
      "[228]\tvalidation_0-auc:0.91231\tvalidation_1-auc:0.83247\n",
      "[229]\tvalidation_0-auc:0.91255\tvalidation_1-auc:0.83239\n",
      "[230]\tvalidation_0-auc:0.91281\tvalidation_1-auc:0.83225\n",
      "[231]\tvalidation_0-auc:0.91286\tvalidation_1-auc:0.83222\n",
      "[232]\tvalidation_0-auc:0.91294\tvalidation_1-auc:0.83224\n",
      "[233]\tvalidation_0-auc:0.91299\tvalidation_1-auc:0.83227\n",
      "[234]\tvalidation_0-auc:0.91317\tvalidation_1-auc:0.83221\n",
      "[235]\tvalidation_0-auc:0.91323\tvalidation_1-auc:0.83221\n",
      "[236]\tvalidation_0-auc:0.91349\tvalidation_1-auc:0.83213\n",
      "[237]\tvalidation_0-auc:0.91351\tvalidation_1-auc:0.83208\n",
      "[238]\tvalidation_0-auc:0.91362\tvalidation_1-auc:0.83204\n",
      "[239]\tvalidation_0-auc:0.91365\tvalidation_1-auc:0.83201\n",
      "[240]\tvalidation_0-auc:0.91370\tvalidation_1-auc:0.83198\n",
      "[241]\tvalidation_0-auc:0.91380\tvalidation_1-auc:0.83197\n",
      "[242]\tvalidation_0-auc:0.91385\tvalidation_1-auc:0.83197\n",
      "[243]\tvalidation_0-auc:0.91387\tvalidation_1-auc:0.83197\n",
      "[244]\tvalidation_0-auc:0.91395\tvalidation_1-auc:0.83204\n",
      "[245]\tvalidation_0-auc:0.91402\tvalidation_1-auc:0.83196\n",
      "ROC AUC: 0.8429\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# n_estimators는 500으로, learning_rate 0.05, random state는 예제 수행 시마다 동일 예측 결과를 위해 설정. \n",
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=0.05, random_state=156)\n",
    "\n",
    "# 성능 평가 지표를 auc로, 조기 중단 파라미터는 100으로 설정하고 학습 수행. \n",
    "xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric='auc', eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38adea69",
   "metadata": {},
   "source": [
    "HyperOpt를 이용해 베이지안 최적화 기반으로 XGBoost의 하이퍼 파라미터 튜닝을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80788ef9",
   "metadata": {},
   "source": [
    "검색 공간 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3df0d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 15까지 1간격으로, min_child_weight는 1에서 6까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 0.95사이, learning_rate는 0.01에서 0.2사이 정규 분포된 값으로 검색. \n",
    "\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 15, 1), \n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbf2bf",
   "metadata": {},
   "source": [
    "목적함수 만들기\n",
    "\n",
    "목적 함수는 3 Fold 교차 검증을 이용해 평균 ROC-AIC 값을 반환하되 -1을 곱해주어 최대 ROC-AUC 값이 최소 반환값이 되게 한다. 교차 검증 시 XGBoost의 조기 중단과 검증 데이터 성능 평가를 위해서 KFold 클래스를 이용하여 직접 학습과 검증 데이터 세트를 추출하고 이를 교차 검증 횟수만큼 학습과 성능 평가를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f90d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 목적 함수 설정. \n",
    "# 추후 fmin()에서 입력된 search_space값으로 XGBClassifier 교차 검증 학습 후 -1* roc_auc 평균 값을 반환.  \n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            learning_rate=search_space['learning_rate']\n",
    "                           )\n",
    "    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list\n",
    "    roc_auc_list= []\n",
    "    \n",
    "    # 3개 k-fold방식 적용 \n",
    "    kf = KFold(n_splits=3)\n",
    "    # X_train을 다시 학습과 검증용 데이터로 분리\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리 \n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행. \n",
    "        xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric='auc',\n",
    "                   eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "    \n",
    "        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음. \n",
    "        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1])\n",
    "        roc_auc_list.append(score)\n",
    "        \n",
    "    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되, \n",
    "    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환. \n",
    "    return -1 * np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adac8a6",
   "metadata": {},
   "source": [
    "fmin() 함수를 호출해 max_eval=50만큼 반복하며 최적의 하이퍼 파라미터 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abcf82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출.\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials, rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500d9b3",
   "metadata": {},
   "source": [
    "comsamplebe_bytree는 약 0.5749, learning_rate가 약 0.1514, max_depth는 5.0, min_child_weight는 6.0이 도출되었다.\n",
    "\n",
    "도출된 최적 하이퍼 파라미터를 기반으로 XGBClassifier를 재학습 시키고 테스트 데이터 세트에서 ROC AUC를 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec026b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators를 500증가 후 최적으로 찾은 하이퍼 파라미터를 기반으로 학습과 예측 수행.\n",
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=round(best['learning_rate'], 5),\n",
    "                        max_depth=int(best['max_depth']), min_child_weight=int(best['min_child_weight']), \n",
    "                        colsample_bytree=round(best['colsample_bytree'], 5)   \n",
    "                       )\n",
    "\n",
    "# evaluation metric을 auc로, early stopping은 100 으로 설정하고 학습 수행. \n",
    "xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=100, \n",
    "            eval_metric=\"auc\",eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896a7c0",
   "metadata": {},
   "source": [
    "튜닝된 모델에서 각 피처의 중요도를 피처 중요도 그래프로 나타내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
    "plot_importance(xgb_clf, ax=ax , max_num_features=20,height=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb57058c",
   "metadata": {},
   "source": [
    "### LightGBM 모델 학습과 하이퍼 파라미터 튜닝\n",
    "\n",
    "LightGBM으로 학습을 수행하고 ROC-AUC를 측정해보기. 학습과 검증 데이터 세트를 이용하여 eval_set=[(X_tr, y_tr), (X_val, y_val)]으로 학습을 진행한 뒤 테스트 데이터 세트로 평가된 ROC-AUC 값을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b0561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.82625\ttraining's binary_logloss: 0.15523\tvalid_1's auc: 0.809814\tvalid_1's binary_logloss: 0.15774\n",
      "[2]\ttraining's auc: 0.833899\ttraining's binary_logloss: 0.149581\tvalid_1's auc: 0.81222\tvalid_1's binary_logloss: 0.153275\n",
      "[3]\ttraining's auc: 0.841789\ttraining's binary_logloss: 0.145416\tvalid_1's auc: 0.814833\tvalid_1's binary_logloss: 0.149999\n",
      "[4]\ttraining's auc: 0.847243\ttraining's binary_logloss: 0.14212\tvalid_1's auc: 0.819406\tvalid_1's binary_logloss: 0.147524\n",
      "[5]\ttraining's auc: 0.849589\ttraining's binary_logloss: 0.139438\tvalid_1's auc: 0.821869\tvalid_1's binary_logloss: 0.145464\n",
      "[6]\ttraining's auc: 0.853413\ttraining's binary_logloss: 0.137254\tvalid_1's auc: 0.820878\tvalid_1's binary_logloss: 0.143973\n",
      "[7]\ttraining's auc: 0.85551\ttraining's binary_logloss: 0.1354\tvalid_1's auc: 0.821815\tvalid_1's binary_logloss: 0.142746\n",
      "[8]\ttraining's auc: 0.858698\ttraining's binary_logloss: 0.133561\tvalid_1's auc: 0.823733\tvalid_1's binary_logloss: 0.141592\n",
      "[9]\ttraining's auc: 0.862123\ttraining's binary_logloss: 0.132058\tvalid_1's auc: 0.825821\tvalid_1's binary_logloss: 0.140633\n",
      "[10]\ttraining's auc: 0.865345\ttraining's binary_logloss: 0.13065\tvalid_1's auc: 0.826285\tvalid_1's binary_logloss: 0.139756\n",
      "[11]\ttraining's auc: 0.867407\ttraining's binary_logloss: 0.129493\tvalid_1's auc: 0.827562\tvalid_1's binary_logloss: 0.139069\n",
      "[12]\ttraining's auc: 0.870828\ttraining's binary_logloss: 0.128398\tvalid_1's auc: 0.827436\tvalid_1's binary_logloss: 0.138559\n",
      "[13]\ttraining's auc: 0.872805\ttraining's binary_logloss: 0.127345\tvalid_1's auc: 0.827656\tvalid_1's binary_logloss: 0.138135\n",
      "[14]\ttraining's auc: 0.875007\ttraining's binary_logloss: 0.126347\tvalid_1's auc: 0.826473\tvalid_1's binary_logloss: 0.137872\n",
      "[15]\ttraining's auc: 0.876836\ttraining's binary_logloss: 0.125429\tvalid_1's auc: 0.826904\tvalid_1's binary_logloss: 0.137519\n",
      "[16]\ttraining's auc: 0.878431\ttraining's binary_logloss: 0.124582\tvalid_1's auc: 0.827524\tvalid_1's binary_logloss: 0.137125\n",
      "[17]\ttraining's auc: 0.879993\ttraining's binary_logloss: 0.123838\tvalid_1's auc: 0.827988\tvalid_1's binary_logloss: 0.136944\n",
      "[18]\ttraining's auc: 0.881612\ttraining's binary_logloss: 0.123118\tvalid_1's auc: 0.829045\tvalid_1's binary_logloss: 0.136749\n",
      "[19]\ttraining's auc: 0.883197\ttraining's binary_logloss: 0.122465\tvalid_1's auc: 0.829311\tvalid_1's binary_logloss: 0.13649\n",
      "[20]\ttraining's auc: 0.884776\ttraining's binary_logloss: 0.121777\tvalid_1's auc: 0.829603\tvalid_1's binary_logloss: 0.136324\n",
      "[21]\ttraining's auc: 0.886842\ttraining's binary_logloss: 0.12111\tvalid_1's auc: 0.829426\tvalid_1's binary_logloss: 0.13621\n",
      "[22]\ttraining's auc: 0.888858\ttraining's binary_logloss: 0.120435\tvalid_1's auc: 0.829605\tvalid_1's binary_logloss: 0.136091\n",
      "[23]\ttraining's auc: 0.889621\ttraining's binary_logloss: 0.119871\tvalid_1's auc: 0.829652\tvalid_1's binary_logloss: 0.135971\n",
      "[24]\ttraining's auc: 0.890866\ttraining's binary_logloss: 0.11938\tvalid_1's auc: 0.829961\tvalid_1's binary_logloss: 0.135886\n",
      "[25]\ttraining's auc: 0.892624\ttraining's binary_logloss: 0.118821\tvalid_1's auc: 0.829862\tvalid_1's binary_logloss: 0.135802\n",
      "[26]\ttraining's auc: 0.894525\ttraining's binary_logloss: 0.118295\tvalid_1's auc: 0.830409\tvalid_1's binary_logloss: 0.13569\n",
      "[27]\ttraining's auc: 0.895856\ttraining's binary_logloss: 0.117824\tvalid_1's auc: 0.83041\tvalid_1's binary_logloss: 0.135642\n",
      "[28]\ttraining's auc: 0.896735\ttraining's binary_logloss: 0.117415\tvalid_1's auc: 0.830191\tvalid_1's binary_logloss: 0.135613\n",
      "[29]\ttraining's auc: 0.89905\ttraining's binary_logloss: 0.116933\tvalid_1's auc: 0.830669\tvalid_1's binary_logloss: 0.135554\n",
      "[30]\ttraining's auc: 0.899896\ttraining's binary_logloss: 0.116506\tvalid_1's auc: 0.83085\tvalid_1's binary_logloss: 0.135507\n",
      "[31]\ttraining's auc: 0.901114\ttraining's binary_logloss: 0.116122\tvalid_1's auc: 0.831318\tvalid_1's binary_logloss: 0.135419\n",
      "[32]\ttraining's auc: 0.902376\ttraining's binary_logloss: 0.115678\tvalid_1's auc: 0.830736\tvalid_1's binary_logloss: 0.135495\n",
      "[33]\ttraining's auc: 0.903176\ttraining's binary_logloss: 0.115337\tvalid_1's auc: 0.831341\tvalid_1's binary_logloss: 0.135413\n",
      "[34]\ttraining's auc: 0.903928\ttraining's binary_logloss: 0.114946\tvalid_1's auc: 0.831809\tvalid_1's binary_logloss: 0.135345\n",
      "[35]\ttraining's auc: 0.904656\ttraining's binary_logloss: 0.114561\tvalid_1's auc: 0.831758\tvalid_1's binary_logloss: 0.135381\n",
      "[36]\ttraining's auc: 0.90615\ttraining's binary_logloss: 0.114188\tvalid_1's auc: 0.831443\tvalid_1's binary_logloss: 0.135392\n",
      "[37]\ttraining's auc: 0.90717\ttraining's binary_logloss: 0.113837\tvalid_1's auc: 0.831706\tvalid_1's binary_logloss: 0.135348\n",
      "[38]\ttraining's auc: 0.908184\ttraining's binary_logloss: 0.113468\tvalid_1's auc: 0.831723\tvalid_1's binary_logloss: 0.135329\n",
      "[39]\ttraining's auc: 0.909007\ttraining's binary_logloss: 0.11311\tvalid_1's auc: 0.831518\tvalid_1's binary_logloss: 0.135355\n",
      "[40]\ttraining's auc: 0.909525\ttraining's binary_logloss: 0.112795\tvalid_1's auc: 0.831749\tvalid_1's binary_logloss: 0.135283\n",
      "[41]\ttraining's auc: 0.910173\ttraining's binary_logloss: 0.112442\tvalid_1's auc: 0.831852\tvalid_1's binary_logloss: 0.135272\n",
      "[42]\ttraining's auc: 0.91059\ttraining's binary_logloss: 0.112183\tvalid_1's auc: 0.831787\tvalid_1's binary_logloss: 0.13527\n",
      "[43]\ttraining's auc: 0.911363\ttraining's binary_logloss: 0.111896\tvalid_1's auc: 0.831339\tvalid_1's binary_logloss: 0.135351\n",
      "[44]\ttraining's auc: 0.912024\ttraining's binary_logloss: 0.111629\tvalid_1's auc: 0.831414\tvalid_1's binary_logloss: 0.135352\n",
      "[45]\ttraining's auc: 0.912839\ttraining's binary_logloss: 0.111221\tvalid_1's auc: 0.831259\tvalid_1's binary_logloss: 0.135367\n",
      "[46]\ttraining's auc: 0.913498\ttraining's binary_logloss: 0.110928\tvalid_1's auc: 0.831154\tvalid_1's binary_logloss: 0.135389\n",
      "[47]\ttraining's auc: 0.913892\ttraining's binary_logloss: 0.11066\tvalid_1's auc: 0.831192\tvalid_1's binary_logloss: 0.135392\n",
      "[48]\ttraining's auc: 0.915067\ttraining's binary_logloss: 0.110329\tvalid_1's auc: 0.831606\tvalid_1's binary_logloss: 0.135323\n",
      "[49]\ttraining's auc: 0.915826\ttraining's binary_logloss: 0.11\tvalid_1's auc: 0.831638\tvalid_1's binary_logloss: 0.135365\n",
      "[50]\ttraining's auc: 0.916562\ttraining's binary_logloss: 0.109711\tvalid_1's auc: 0.831734\tvalid_1's binary_logloss: 0.13536\n",
      "[51]\ttraining's auc: 0.917206\ttraining's binary_logloss: 0.109469\tvalid_1's auc: 0.831617\tvalid_1's binary_logloss: 0.135393\n",
      "[52]\ttraining's auc: 0.917536\ttraining's binary_logloss: 0.109235\tvalid_1's auc: 0.831257\tvalid_1's binary_logloss: 0.135442\n",
      "[53]\ttraining's auc: 0.917907\ttraining's binary_logloss: 0.108987\tvalid_1's auc: 0.831382\tvalid_1's binary_logloss: 0.135437\n",
      "[54]\ttraining's auc: 0.918284\ttraining's binary_logloss: 0.108769\tvalid_1's auc: 0.831495\tvalid_1's binary_logloss: 0.135434\n",
      "[55]\ttraining's auc: 0.918573\ttraining's binary_logloss: 0.108589\tvalid_1's auc: 0.831495\tvalid_1's binary_logloss: 0.135415\n",
      "[56]\ttraining's auc: 0.918935\ttraining's binary_logloss: 0.108409\tvalid_1's auc: 0.831518\tvalid_1's binary_logloss: 0.135406\n",
      "[57]\ttraining's auc: 0.919173\ttraining's binary_logloss: 0.10824\tvalid_1's auc: 0.831656\tvalid_1's binary_logloss: 0.135386\n",
      "[58]\ttraining's auc: 0.919779\ttraining's binary_logloss: 0.108043\tvalid_1's auc: 0.831551\tvalid_1's binary_logloss: 0.135417\n",
      "[59]\ttraining's auc: 0.920357\ttraining's binary_logloss: 0.107751\tvalid_1's auc: 0.8317\tvalid_1's binary_logloss: 0.135425\n",
      "[60]\ttraining's auc: 0.92059\ttraining's binary_logloss: 0.107571\tvalid_1's auc: 0.8319\tvalid_1's binary_logloss: 0.135368\n",
      "[61]\ttraining's auc: 0.920797\ttraining's binary_logloss: 0.107442\tvalid_1's auc: 0.831807\tvalid_1's binary_logloss: 0.135378\n",
      "[62]\ttraining's auc: 0.921181\ttraining's binary_logloss: 0.107241\tvalid_1's auc: 0.831859\tvalid_1's binary_logloss: 0.135393\n",
      "[63]\ttraining's auc: 0.922297\ttraining's binary_logloss: 0.106885\tvalid_1's auc: 0.831503\tvalid_1's binary_logloss: 0.135484\n",
      "[64]\ttraining's auc: 0.922813\ttraining's binary_logloss: 0.10663\tvalid_1's auc: 0.831716\tvalid_1's binary_logloss: 0.135438\n",
      "[65]\ttraining's auc: 0.923479\ttraining's binary_logloss: 0.106343\tvalid_1's auc: 0.831698\tvalid_1's binary_logloss: 0.135468\n",
      "[66]\ttraining's auc: 0.923773\ttraining's binary_logloss: 0.106134\tvalid_1's auc: 0.831502\tvalid_1's binary_logloss: 0.135547\n",
      "[67]\ttraining's auc: 0.923991\ttraining's binary_logloss: 0.105977\tvalid_1's auc: 0.831669\tvalid_1's binary_logloss: 0.135537\n",
      "[68]\ttraining's auc: 0.924656\ttraining's binary_logloss: 0.105802\tvalid_1's auc: 0.831775\tvalid_1's binary_logloss: 0.135525\n",
      "[69]\ttraining's auc: 0.925273\ttraining's binary_logloss: 0.105548\tvalid_1's auc: 0.831952\tvalid_1's binary_logloss: 0.135527\n",
      "[70]\ttraining's auc: 0.925899\ttraining's binary_logloss: 0.105314\tvalid_1's auc: 0.831659\tvalid_1's binary_logloss: 0.135611\n",
      "[71]\ttraining's auc: 0.926827\ttraining's binary_logloss: 0.105054\tvalid_1's auc: 0.831626\tvalid_1's binary_logloss: 0.135621\n",
      "[72]\ttraining's auc: 0.927861\ttraining's binary_logloss: 0.104712\tvalid_1's auc: 0.831612\tvalid_1's binary_logloss: 0.135665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73]\ttraining's auc: 0.928078\ttraining's binary_logloss: 0.104537\tvalid_1's auc: 0.831395\tvalid_1's binary_logloss: 0.135709\n",
      "[74]\ttraining's auc: 0.928329\ttraining's binary_logloss: 0.104353\tvalid_1's auc: 0.831106\tvalid_1's binary_logloss: 0.135773\n",
      "[75]\ttraining's auc: 0.928639\ttraining's binary_logloss: 0.104167\tvalid_1's auc: 0.83094\tvalid_1's binary_logloss: 0.135819\n",
      "[76]\ttraining's auc: 0.928812\ttraining's binary_logloss: 0.104032\tvalid_1's auc: 0.831078\tvalid_1's binary_logloss: 0.135819\n",
      "[77]\ttraining's auc: 0.929094\ttraining's binary_logloss: 0.103841\tvalid_1's auc: 0.831173\tvalid_1's binary_logloss: 0.135831\n",
      "[78]\ttraining's auc: 0.929304\ttraining's binary_logloss: 0.103661\tvalid_1's auc: 0.831108\tvalid_1's binary_logloss: 0.135854\n",
      "[79]\ttraining's auc: 0.929558\ttraining's binary_logloss: 0.103444\tvalid_1's auc: 0.830932\tvalid_1's binary_logloss: 0.135942\n",
      "[80]\ttraining's auc: 0.930062\ttraining's binary_logloss: 0.103185\tvalid_1's auc: 0.831212\tvalid_1's binary_logloss: 0.135846\n",
      "[81]\ttraining's auc: 0.93021\ttraining's binary_logloss: 0.103035\tvalid_1's auc: 0.831221\tvalid_1's binary_logloss: 0.13587\n",
      "[82]\ttraining's auc: 0.930873\ttraining's binary_logloss: 0.102757\tvalid_1's auc: 0.831112\tvalid_1's binary_logloss: 0.135917\n",
      "[83]\ttraining's auc: 0.931024\ttraining's binary_logloss: 0.102636\tvalid_1's auc: 0.831065\tvalid_1's binary_logloss: 0.135936\n",
      "[84]\ttraining's auc: 0.931479\ttraining's binary_logloss: 0.102405\tvalid_1's auc: 0.830915\tvalid_1's binary_logloss: 0.135993\n",
      "[85]\ttraining's auc: 0.931704\ttraining's binary_logloss: 0.102221\tvalid_1's auc: 0.831007\tvalid_1's binary_logloss: 0.135984\n",
      "[86]\ttraining's auc: 0.931863\ttraining's binary_logloss: 0.1021\tvalid_1's auc: 0.831073\tvalid_1's binary_logloss: 0.135943\n",
      "[87]\ttraining's auc: 0.932249\ttraining's binary_logloss: 0.101879\tvalid_1's auc: 0.831022\tvalid_1's binary_logloss: 0.135962\n",
      "[88]\ttraining's auc: 0.932765\ttraining's binary_logloss: 0.101605\tvalid_1's auc: 0.830827\tvalid_1's binary_logloss: 0.136022\n",
      "[89]\ttraining's auc: 0.933029\ttraining's binary_logloss: 0.101427\tvalid_1's auc: 0.830847\tvalid_1's binary_logloss: 0.13606\n",
      "[90]\ttraining's auc: 0.933574\ttraining's binary_logloss: 0.101132\tvalid_1's auc: 0.830845\tvalid_1's binary_logloss: 0.136074\n",
      "[91]\ttraining's auc: 0.933718\ttraining's binary_logloss: 0.100966\tvalid_1's auc: 0.831067\tvalid_1's binary_logloss: 0.136028\n",
      "[92]\ttraining's auc: 0.933882\ttraining's binary_logloss: 0.100834\tvalid_1's auc: 0.830966\tvalid_1's binary_logloss: 0.13606\n",
      "[93]\ttraining's auc: 0.934042\ttraining's binary_logloss: 0.100677\tvalid_1's auc: 0.830691\tvalid_1's binary_logloss: 0.136126\n",
      "[94]\ttraining's auc: 0.934515\ttraining's binary_logloss: 0.100417\tvalid_1's auc: 0.830759\tvalid_1's binary_logloss: 0.136153\n",
      "[95]\ttraining's auc: 0.934868\ttraining's binary_logloss: 0.100212\tvalid_1's auc: 0.830436\tvalid_1's binary_logloss: 0.136221\n",
      "[96]\ttraining's auc: 0.935009\ttraining's binary_logloss: 0.1001\tvalid_1's auc: 0.830566\tvalid_1's binary_logloss: 0.136227\n",
      "[97]\ttraining's auc: 0.935251\ttraining's binary_logloss: 0.0999167\tvalid_1's auc: 0.830664\tvalid_1's binary_logloss: 0.13623\n",
      "[98]\ttraining's auc: 0.935506\ttraining's binary_logloss: 0.0997379\tvalid_1's auc: 0.830618\tvalid_1's binary_logloss: 0.13627\n",
      "[99]\ttraining's auc: 0.935882\ttraining's binary_logloss: 0.0995979\tvalid_1's auc: 0.830275\tvalid_1's binary_logloss: 0.136349\n",
      "[100]\ttraining's auc: 0.936241\ttraining's binary_logloss: 0.0993852\tvalid_1's auc: 0.830154\tvalid_1's binary_logloss: 0.136377\n",
      "[101]\ttraining's auc: 0.936333\ttraining's binary_logloss: 0.0992904\tvalid_1's auc: 0.830043\tvalid_1's binary_logloss: 0.136418\n",
      "[102]\ttraining's auc: 0.9367\ttraining's binary_logloss: 0.0990862\tvalid_1's auc: 0.829994\tvalid_1's binary_logloss: 0.13649\n",
      "[103]\ttraining's auc: 0.936984\ttraining's binary_logloss: 0.0989027\tvalid_1's auc: 0.830189\tvalid_1's binary_logloss: 0.136458\n",
      "[104]\ttraining's auc: 0.937129\ttraining's binary_logloss: 0.098774\tvalid_1's auc: 0.830084\tvalid_1's binary_logloss: 0.136529\n",
      "[105]\ttraining's auc: 0.937202\ttraining's binary_logloss: 0.0986737\tvalid_1's auc: 0.829896\tvalid_1's binary_logloss: 0.13659\n",
      "[106]\ttraining's auc: 0.937564\ttraining's binary_logloss: 0.0984463\tvalid_1's auc: 0.829901\tvalid_1's binary_logloss: 0.136565\n",
      "[107]\ttraining's auc: 0.937841\ttraining's binary_logloss: 0.0983149\tvalid_1's auc: 0.830041\tvalid_1's binary_logloss: 0.136565\n",
      "[108]\ttraining's auc: 0.938216\ttraining's binary_logloss: 0.098084\tvalid_1's auc: 0.83014\tvalid_1's binary_logloss: 0.136553\n",
      "[109]\ttraining's auc: 0.938267\ttraining's binary_logloss: 0.0980124\tvalid_1's auc: 0.830141\tvalid_1's binary_logloss: 0.136539\n",
      "[110]\ttraining's auc: 0.938407\ttraining's binary_logloss: 0.0978703\tvalid_1's auc: 0.830052\tvalid_1's binary_logloss: 0.136566\n",
      "[111]\ttraining's auc: 0.93931\ttraining's binary_logloss: 0.09755\tvalid_1's auc: 0.829724\tvalid_1's binary_logloss: 0.136676\n",
      "[112]\ttraining's auc: 0.939421\ttraining's binary_logloss: 0.0974606\tvalid_1's auc: 0.829726\tvalid_1's binary_logloss: 0.136717\n",
      "[113]\ttraining's auc: 0.939745\ttraining's binary_logloss: 0.0973115\tvalid_1's auc: 0.829762\tvalid_1's binary_logloss: 0.136724\n",
      "[114]\ttraining's auc: 0.940126\ttraining's binary_logloss: 0.0970794\tvalid_1's auc: 0.829718\tvalid_1's binary_logloss: 0.136816\n",
      "[115]\ttraining's auc: 0.940527\ttraining's binary_logloss: 0.0968341\tvalid_1's auc: 0.829629\tvalid_1's binary_logloss: 0.136873\n",
      "[116]\ttraining's auc: 0.940641\ttraining's binary_logloss: 0.0966994\tvalid_1's auc: 0.829556\tvalid_1's binary_logloss: 0.136899\n",
      "[117]\ttraining's auc: 0.941227\ttraining's binary_logloss: 0.0964334\tvalid_1's auc: 0.829605\tvalid_1's binary_logloss: 0.136933\n",
      "[118]\ttraining's auc: 0.941656\ttraining's binary_logloss: 0.0961947\tvalid_1's auc: 0.829688\tvalid_1's binary_logloss: 0.136933\n",
      "[119]\ttraining's auc: 0.941748\ttraining's binary_logloss: 0.0960705\tvalid_1's auc: 0.829666\tvalid_1's binary_logloss: 0.136953\n",
      "[120]\ttraining's auc: 0.94216\ttraining's binary_logloss: 0.0958417\tvalid_1's auc: 0.829622\tvalid_1's binary_logloss: 0.136997\n",
      "[121]\ttraining's auc: 0.94238\ttraining's binary_logloss: 0.0956645\tvalid_1's auc: 0.829516\tvalid_1's binary_logloss: 0.137036\n",
      "[122]\ttraining's auc: 0.942499\ttraining's binary_logloss: 0.0955579\tvalid_1's auc: 0.829434\tvalid_1's binary_logloss: 0.137052\n",
      "[123]\ttraining's auc: 0.942588\ttraining's binary_logloss: 0.0954606\tvalid_1's auc: 0.829298\tvalid_1's binary_logloss: 0.137111\n",
      "[124]\ttraining's auc: 0.942943\ttraining's binary_logloss: 0.0952291\tvalid_1's auc: 0.829389\tvalid_1's binary_logloss: 0.137106\n",
      "[125]\ttraining's auc: 0.943424\ttraining's binary_logloss: 0.0950165\tvalid_1's auc: 0.829568\tvalid_1's binary_logloss: 0.137063\n",
      "[126]\ttraining's auc: 0.943549\ttraining's binary_logloss: 0.0949034\tvalid_1's auc: 0.82942\tvalid_1's binary_logloss: 0.137116\n",
      "[127]\ttraining's auc: 0.943906\ttraining's binary_logloss: 0.0946862\tvalid_1's auc: 0.829425\tvalid_1's binary_logloss: 0.137126\n",
      "[128]\ttraining's auc: 0.9441\ttraining's binary_logloss: 0.0945286\tvalid_1's auc: 0.829372\tvalid_1's binary_logloss: 0.137162\n",
      "[129]\ttraining's auc: 0.944404\ttraining's binary_logloss: 0.0943193\tvalid_1's auc: 0.829456\tvalid_1's binary_logloss: 0.137161\n",
      "[130]\ttraining's auc: 0.944786\ttraining's binary_logloss: 0.0940784\tvalid_1's auc: 0.829409\tvalid_1's binary_logloss: 0.137231\n",
      "[131]\ttraining's auc: 0.944991\ttraining's binary_logloss: 0.0939332\tvalid_1's auc: 0.82933\tvalid_1's binary_logloss: 0.13726\n",
      "[132]\ttraining's auc: 0.945083\ttraining's binary_logloss: 0.0938351\tvalid_1's auc: 0.829237\tvalid_1's binary_logloss: 0.137312\n",
      "[133]\ttraining's auc: 0.945246\ttraining's binary_logloss: 0.09369\tvalid_1's auc: 0.829071\tvalid_1's binary_logloss: 0.137368\n",
      "[134]\ttraining's auc: 0.945545\ttraining's binary_logloss: 0.0935468\tvalid_1's auc: 0.829027\tvalid_1's binary_logloss: 0.137391\n",
      "[135]\ttraining's auc: 0.946253\ttraining's binary_logloss: 0.0933204\tvalid_1's auc: 0.829006\tvalid_1's binary_logloss: 0.13739\n",
      "[136]\ttraining's auc: 0.946589\ttraining's binary_logloss: 0.0931143\tvalid_1's auc: 0.829054\tvalid_1's binary_logloss: 0.137403\n",
      "[137]\ttraining's auc: 0.946772\ttraining's binary_logloss: 0.092979\tvalid_1's auc: 0.828949\tvalid_1's binary_logloss: 0.137447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138]\ttraining's auc: 0.946832\ttraining's binary_logloss: 0.0929083\tvalid_1's auc: 0.828907\tvalid_1's binary_logloss: 0.137476\n",
      "[139]\ttraining's auc: 0.947105\ttraining's binary_logloss: 0.0927328\tvalid_1's auc: 0.829034\tvalid_1's binary_logloss: 0.137463\n",
      "[140]\ttraining's auc: 0.94779\ttraining's binary_logloss: 0.0924716\tvalid_1's auc: 0.829175\tvalid_1's binary_logloss: 0.137451\n",
      "[141]\ttraining's auc: 0.948038\ttraining's binary_logloss: 0.0923201\tvalid_1's auc: 0.829218\tvalid_1's binary_logloss: 0.137468\n",
      "[142]\ttraining's auc: 0.948302\ttraining's binary_logloss: 0.0921179\tvalid_1's auc: 0.829267\tvalid_1's binary_logloss: 0.137482\n",
      "ROC AUC: 0.8384\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=500)\n",
    "\n",
    "eval_set=[(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464ed80",
   "metadata": {},
   "source": [
    "HyperOpt를 이용하여 다양한 하이퍼 파라미터에 대한 튜닝을 수행하기\n",
    "\n",
    "하이퍼 파라미터 검색 공간 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1c1c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n",
    "                     'max_depth': hp.quniform('max_depth', 100, 160, 1),\n",
    "                     'min_child_samples': hp.quniform('min_child_samples', 60, 100, 1),\n",
    "                     'subsample': hp.uniform('subsample', 0.7, 1),\n",
    "                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa9d3c",
   "metadata": {},
   "source": [
    "목적 함수 생성\n",
    "\n",
    "XGBoost와 크게 다르지 않으며, LGBMClassifier 객체를 생성하는 부분만 달라진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "884773fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space):\n",
    "    lgbm_clf =  LGBMClassifier(n_estimators=100, num_leaves=int(search_space['num_leaves']),\n",
    "                               max_depth=int(search_space['max_depth']),\n",
    "                               min_child_samples=int(search_space['min_child_samples']), \n",
    "                               subsample=search_space['subsample'],\n",
    "                               learning_rate=search_space['learning_rate'])\n",
    "    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list\n",
    "    roc_auc_list = []\n",
    "    \n",
    "    # 3개 k-fold방식 적용 \n",
    "    kf = KFold(n_splits=3)\n",
    "    # X_train을 다시 학습과 검증용 데이터로 분리\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리 \n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행. \n",
    "        lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric=\"auc\",\n",
    "           eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "        # 1로 예측한 확률값 추출후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결과값 담음.\n",
    "        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1]) \n",
    "        roc_auc_list.append(score)\n",
    "    \n",
    "    # 3개 k-fold로 계산된 roc_auc값의 평균값을 반환하되, \n",
    "    # HyperOpt는 목적함수의 최소값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환.\n",
    "    return -1*np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01091b11",
   "metadata": {},
   "source": [
    "fmin()을 호출하여 최적 하이퍼 파라미터를 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85858e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.82736\ttraining's binary_logloss: 0.162294\tvalid_1's auc: 0.804818\tvalid_1's binary_logloss: 0.163544\n",
      "[2]\ttraining's auc: 0.828309\ttraining's binary_logloss: 0.160269\tvalid_1's auc: 0.804585\tvalid_1's binary_logloss: 0.161866\n",
      "[3]\ttraining's auc: 0.833368\ttraining's binary_logloss: 0.158478\tvalid_1's auc: 0.806871\tvalid_1's binary_logloss: 0.16038\n",
      "[4]\ttraining's auc: 0.834671\ttraining's binary_logloss: 0.156852\tvalid_1's auc: 0.80706\tvalid_1's binary_logloss: 0.159053\n",
      "[5]\ttraining's auc: 0.837783\ttraining's binary_logloss: 0.155354\tvalid_1's auc: 0.811645\tvalid_1's binary_logloss: 0.157793\n",
      "[6]\ttraining's auc: 0.839052\ttraining's binary_logloss: 0.153966\tvalid_1's auc: 0.81271\tvalid_1's binary_logloss: 0.156635\n",
      "[7]\ttraining's auc: 0.841216\ttraining's binary_logloss: 0.152691\tvalid_1's auc: 0.815103\tvalid_1's binary_logloss: 0.155585\n",
      "[8]\ttraining's auc: 0.841859\ttraining's binary_logloss: 0.151499\tvalid_1's auc: 0.814773\tvalid_1's binary_logloss: 0.154617\n",
      "[9]\ttraining's auc: 0.844543\ttraining's binary_logloss: 0.150393\tvalid_1's auc: 0.816663\tvalid_1's binary_logloss: 0.153725\n",
      "[10]\ttraining's auc: 0.845228\ttraining's binary_logloss: 0.149346\tvalid_1's auc: 0.816528\tvalid_1's binary_logloss: 0.152878\n",
      "[11]\ttraining's auc: 0.8479\ttraining's binary_logloss: 0.148364\tvalid_1's auc: 0.818315\tvalid_1's binary_logloss: 0.152101\n",
      "[12]\ttraining's auc: 0.848789\ttraining's binary_logloss: 0.147436\tvalid_1's auc: 0.818839\tvalid_1's binary_logloss: 0.151369\n",
      "[13]\ttraining's auc: 0.849537\ttraining's binary_logloss: 0.146567\tvalid_1's auc: 0.82048\tvalid_1's binary_logloss: 0.150661\n",
      "[14]\ttraining's auc: 0.850363\ttraining's binary_logloss: 0.145732\tvalid_1's auc: 0.820545\tvalid_1's binary_logloss: 0.150023\n",
      "[15]\ttraining's auc: 0.851536\ttraining's binary_logloss: 0.144941\tvalid_1's auc: 0.821707\tvalid_1's binary_logloss: 0.149388\n",
      "[16]\ttraining's auc: 0.852542\ttraining's binary_logloss: 0.14421\tvalid_1's auc: 0.822234\tvalid_1's binary_logloss: 0.148805\n",
      "[17]\ttraining's auc: 0.853019\ttraining's binary_logloss: 0.143458\tvalid_1's auc: 0.822418\tvalid_1's binary_logloss: 0.148223\n",
      "[18]\ttraining's auc: 0.854924\ttraining's binary_logloss: 0.142757\tvalid_1's auc: 0.823738\tvalid_1's binary_logloss: 0.147689\n",
      "[19]\ttraining's auc: 0.855156\ttraining's binary_logloss: 0.142099\tvalid_1's auc: 0.824535\tvalid_1's binary_logloss: 0.147136\n",
      "[20]\ttraining's auc: 0.855564\ttraining's binary_logloss: 0.141467\tvalid_1's auc: 0.824824\tvalid_1's binary_logloss: 0.146639\n",
      "[21]\ttraining's auc: 0.856772\ttraining's binary_logloss: 0.14086\tvalid_1's auc: 0.825749\tvalid_1's binary_logloss: 0.14617\n",
      "[22]\ttraining's auc: 0.857006\ttraining's binary_logloss: 0.140279\tvalid_1's auc: 0.826089\tvalid_1's binary_logloss: 0.14572\n",
      "[23]\ttraining's auc: 0.8577\ttraining's binary_logloss: 0.13973\tvalid_1's auc: 0.826044\tvalid_1's binary_logloss: 0.145315\n",
      "[24]\ttraining's auc: 0.857878\ttraining's binary_logloss: 0.139206\tvalid_1's auc: 0.825979\tvalid_1's binary_logloss: 0.144946\n",
      "[25]\ttraining's auc: 0.85788\ttraining's binary_logloss: 0.138692\tvalid_1's auc: 0.825977\tvalid_1's binary_logloss: 0.144561\n",
      "[26]\ttraining's auc: 0.85796\ttraining's binary_logloss: 0.13821\tvalid_1's auc: 0.82609\tvalid_1's binary_logloss: 0.144213\n",
      "[27]\ttraining's auc: 0.858746\ttraining's binary_logloss: 0.137726\tvalid_1's auc: 0.826481\tvalid_1's binary_logloss: 0.143852\n",
      "[28]\ttraining's auc: 0.859159\ttraining's binary_logloss: 0.137267\tvalid_1's auc: 0.826417\tvalid_1's binary_logloss: 0.143505\n",
      "[29]\ttraining's auc: 0.86041\ttraining's binary_logloss: 0.136829\tvalid_1's auc: 0.826777\tvalid_1's binary_logloss: 0.143175\n",
      "[30]\ttraining's auc: 0.860868\ttraining's binary_logloss: 0.136398\tvalid_1's auc: 0.826976\tvalid_1's binary_logloss: 0.142884\n",
      "[31]\ttraining's auc: 0.86107\ttraining's binary_logloss: 0.13599\tvalid_1's auc: 0.826882\tvalid_1's binary_logloss: 0.142616\n",
      "[32]\ttraining's auc: 0.861254\ttraining's binary_logloss: 0.135587\tvalid_1's auc: 0.826343\tvalid_1's binary_logloss: 0.142359\n",
      "[33]\ttraining's auc: 0.861675\ttraining's binary_logloss: 0.135193\tvalid_1's auc: 0.826727\tvalid_1's binary_logloss: 0.142075\n",
      "[34]\ttraining's auc: 0.862184\ttraining's binary_logloss: 0.134816\tvalid_1's auc: 0.826725\tvalid_1's binary_logloss: 0.141828\n",
      "[35]\ttraining's auc: 0.86269\ttraining's binary_logloss: 0.134453\tvalid_1's auc: 0.82723\tvalid_1's binary_logloss: 0.141553\n",
      "[36]\ttraining's auc: 0.862869\ttraining's binary_logloss: 0.134105\tvalid_1's auc: 0.827332\tvalid_1's binary_logloss: 0.1413\n",
      "[37]\ttraining's auc: 0.863113\ttraining's binary_logloss: 0.133774\tvalid_1's auc: 0.827675\tvalid_1's binary_logloss: 0.141066\n",
      "[38]\ttraining's auc: 0.864227\ttraining's binary_logloss: 0.133438\tvalid_1's auc: 0.827587\tvalid_1's binary_logloss: 0.140849\n",
      "[39]\ttraining's auc: 0.864575\ttraining's binary_logloss: 0.133118\tvalid_1's auc: 0.827714\tvalid_1's binary_logloss: 0.140649\n",
      "[40]\ttraining's auc: 0.864869\ttraining's binary_logloss: 0.132804\tvalid_1's auc: 0.827789\tvalid_1's binary_logloss: 0.140459\n",
      "[41]\ttraining's auc: 0.865372\ttraining's binary_logloss: 0.132476\tvalid_1's auc: 0.828011\tvalid_1's binary_logloss: 0.140263\n",
      "[42]\ttraining's auc: 0.865899\ttraining's binary_logloss: 0.132178\tvalid_1's auc: 0.827975\tvalid_1's binary_logloss: 0.140097\n",
      "[43]\ttraining's auc: 0.8662\ttraining's binary_logloss: 0.131873\tvalid_1's auc: 0.828199\tvalid_1's binary_logloss: 0.139924\n",
      "[44]\ttraining's auc: 0.866291\ttraining's binary_logloss: 0.131582\tvalid_1's auc: 0.828127\tvalid_1's binary_logloss: 0.139765\n",
      "[45]\ttraining's auc: 0.867193\ttraining's binary_logloss: 0.131295\tvalid_1's auc: 0.828463\tvalid_1's binary_logloss: 0.139591\n",
      "[46]\ttraining's auc: 0.86755\ttraining's binary_logloss: 0.131011\tvalid_1's auc: 0.828484\tvalid_1's binary_logloss: 0.139422\n",
      "[47]\ttraining's auc: 0.868151\ttraining's binary_logloss: 0.130742\tvalid_1's auc: 0.828661\tvalid_1's binary_logloss: 0.139264\n",
      "[48]\ttraining's auc: 0.868467\ttraining's binary_logloss: 0.130483\tvalid_1's auc: 0.828577\tvalid_1's binary_logloss: 0.139142\n",
      "[49]\ttraining's auc: 0.869009\ttraining's binary_logloss: 0.130233\tvalid_1's auc: 0.828612\tvalid_1's binary_logloss: 0.13901\n",
      "[50]\ttraining's auc: 0.869341\ttraining's binary_logloss: 0.130003\tvalid_1's auc: 0.828544\tvalid_1's binary_logloss: 0.138887\n",
      "[51]\ttraining's auc: 0.869923\ttraining's binary_logloss: 0.129754\tvalid_1's auc: 0.828647\tvalid_1's binary_logloss: 0.138754\n",
      "[52]\ttraining's auc: 0.870435\ttraining's binary_logloss: 0.129523\tvalid_1's auc: 0.828877\tvalid_1's binary_logloss: 0.138622\n",
      "[53]\ttraining's auc: 0.870843\ttraining's binary_logloss: 0.129293\tvalid_1's auc: 0.828691\tvalid_1's binary_logloss: 0.13851\n",
      "[54]\ttraining's auc: 0.871421\ttraining's binary_logloss: 0.129056\tvalid_1's auc: 0.828891\tvalid_1's binary_logloss: 0.138378\n",
      "[55]\ttraining's auc: 0.87172\ttraining's binary_logloss: 0.128844\tvalid_1's auc: 0.829102\tvalid_1's binary_logloss: 0.138264\n",
      "[56]\ttraining's auc: 0.87216\ttraining's binary_logloss: 0.128617\tvalid_1's auc: 0.829113\tvalid_1's binary_logloss: 0.138145\n",
      "[57]\ttraining's auc: 0.872412\ttraining's binary_logloss: 0.128414\tvalid_1's auc: 0.82926\tvalid_1's binary_logloss: 0.138033\n",
      "[58]\ttraining's auc: 0.872885\ttraining's binary_logloss: 0.1282\tvalid_1's auc: 0.829445\tvalid_1's binary_logloss: 0.137916\n",
      "[59]\ttraining's auc: 0.873194\ttraining's binary_logloss: 0.128005\tvalid_1's auc: 0.829547\tvalid_1's binary_logloss: 0.137814\n",
      "[60]\ttraining's auc: 0.873606\ttraining's binary_logloss: 0.127798\tvalid_1's auc: 0.829606\tvalid_1's binary_logloss: 0.137711\n",
      "[61]\ttraining's auc: 0.873942\ttraining's binary_logloss: 0.127601\tvalid_1's auc: 0.82973\tvalid_1's binary_logloss: 0.13761\n",
      "[62]\ttraining's auc: 0.874359\ttraining's binary_logloss: 0.127396\tvalid_1's auc: 0.829856\tvalid_1's binary_logloss: 0.13752\n",
      "[63]\ttraining's auc: 0.874868\ttraining's binary_logloss: 0.1272\tvalid_1's auc: 0.829787\tvalid_1's binary_logloss: 0.137451\n",
      "[64]\ttraining's auc: 0.875214\ttraining's binary_logloss: 0.127008\tvalid_1's auc: 0.829883\tvalid_1's binary_logloss: 0.137368\n",
      "[65]\ttraining's auc: 0.87576\ttraining's binary_logloss: 0.126819\tvalid_1's auc: 0.829913\tvalid_1's binary_logloss: 0.137293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66]\ttraining's auc: 0.876244\ttraining's binary_logloss: 0.126639\tvalid_1's auc: 0.829919\tvalid_1's binary_logloss: 0.137223\n",
      "[67]\ttraining's auc: 0.876733\ttraining's binary_logloss: 0.126457\tvalid_1's auc: 0.829943\tvalid_1's binary_logloss: 0.137148\n",
      "[68]\ttraining's auc: 0.877004\ttraining's binary_logloss: 0.126282\tvalid_1's auc: 0.829954\tvalid_1's binary_logloss: 0.137083\n",
      "[69]\ttraining's auc: 0.87756\ttraining's binary_logloss: 0.1261\tvalid_1's auc: 0.830128\tvalid_1's binary_logloss: 0.137018\n",
      "[70]\ttraining's auc: 0.87797\ttraining's binary_logloss: 0.12593\tvalid_1's auc: 0.830009\tvalid_1's binary_logloss: 0.136959\n",
      "[71]\ttraining's auc: 0.878271\ttraining's binary_logloss: 0.125757\tvalid_1's auc: 0.83006\tvalid_1's binary_logloss: 0.136874\n",
      "[72]\ttraining's auc: 0.878636\ttraining's binary_logloss: 0.125587\tvalid_1's auc: 0.830076\tvalid_1's binary_logloss: 0.136826\n",
      "[73]\ttraining's auc: 0.879184\ttraining's binary_logloss: 0.125399\tvalid_1's auc: 0.830085\tvalid_1's binary_logloss: 0.136789\n",
      "[74]\ttraining's auc: 0.879469\ttraining's binary_logloss: 0.125237\tvalid_1's auc: 0.830075\tvalid_1's binary_logloss: 0.136732\n",
      "[75]\ttraining's auc: 0.879964\ttraining's binary_logloss: 0.125056\tvalid_1's auc: 0.830222\tvalid_1's binary_logloss: 0.136685\n",
      "[76]\ttraining's auc: 0.880303\ttraining's binary_logloss: 0.124899\tvalid_1's auc: 0.830241\tvalid_1's binary_logloss: 0.136648\n",
      "[77]\ttraining's auc: 0.88089\ttraining's binary_logloss: 0.124722\tvalid_1's auc: 0.830215\tvalid_1's binary_logloss: 0.136597\n",
      "[78]\ttraining's auc: 0.881192\ttraining's binary_logloss: 0.124574\tvalid_1's auc: 0.830266\tvalid_1's binary_logloss: 0.136547\n",
      "[79]\ttraining's auc: 0.881363\ttraining's binary_logloss: 0.124436\tvalid_1's auc: 0.830499\tvalid_1's binary_logloss: 0.136479\n",
      "[80]\ttraining's auc: 0.881666\ttraining's binary_logloss: 0.124293\tvalid_1's auc: 0.830716\tvalid_1's binary_logloss: 0.136417\n",
      "[81]\ttraining's auc: 0.881924\ttraining's binary_logloss: 0.124142\tvalid_1's auc: 0.830713\tvalid_1's binary_logloss: 0.136371\n",
      "[82]\ttraining's auc: 0.882378\ttraining's binary_logloss: 0.123993\tvalid_1's auc: 0.830755\tvalid_1's binary_logloss: 0.136333\n",
      "[83]\ttraining's auc: 0.882585\ttraining's binary_logloss: 0.123854\tvalid_1's auc: 0.830732\tvalid_1's binary_logloss: 0.136295\n",
      "[84]\ttraining's auc: 0.882911\ttraining's binary_logloss: 0.123715\tvalid_1's auc: 0.83068\tvalid_1's binary_logloss: 0.136272\n",
      "[85]\ttraining's auc: 0.883229\ttraining's binary_logloss: 0.123574\tvalid_1's auc: 0.830717\tvalid_1's binary_logloss: 0.136235\n",
      "[86]\ttraining's auc: 0.883497\ttraining's binary_logloss: 0.123438\tvalid_1's auc: 0.830844\tvalid_1's binary_logloss: 0.136201\n",
      "[87]\ttraining's auc: 0.883822\ttraining's binary_logloss: 0.123296\tvalid_1's auc: 0.830747\tvalid_1's binary_logloss: 0.136165\n",
      "[88]\ttraining's auc: 0.884093\ttraining's binary_logloss: 0.123163\tvalid_1's auc: 0.830845\tvalid_1's binary_logloss: 0.136136\n",
      "[89]\ttraining's auc: 0.884391\ttraining's binary_logloss: 0.123021\tvalid_1's auc: 0.830922\tvalid_1's binary_logloss: 0.136103\n",
      "[90]\ttraining's auc: 0.884729\ttraining's binary_logloss: 0.122885\tvalid_1's auc: 0.830912\tvalid_1's binary_logloss: 0.136081\n",
      "[91]\ttraining's auc: 0.885214\ttraining's binary_logloss: 0.12273\tvalid_1's auc: 0.830915\tvalid_1's binary_logloss: 0.136065\n",
      "[92]\ttraining's auc: 0.885589\ttraining's binary_logloss: 0.122593\tvalid_1's auc: 0.830956\tvalid_1's binary_logloss: 0.136041\n",
      "[93]\ttraining's auc: 0.885884\ttraining's binary_logloss: 0.122452\tvalid_1's auc: 0.830832\tvalid_1's binary_logloss: 0.13604\n",
      "[94]\ttraining's auc: 0.886093\ttraining's binary_logloss: 0.122337\tvalid_1's auc: 0.830805\tvalid_1's binary_logloss: 0.136025\n",
      "[95]\ttraining's auc: 0.886763\ttraining's binary_logloss: 0.122187\tvalid_1's auc: 0.831188\tvalid_1's binary_logloss: 0.135958\n",
      "[96]\ttraining's auc: 0.88694\ttraining's binary_logloss: 0.122068\tvalid_1's auc: 0.831232\tvalid_1's binary_logloss: 0.135925\n",
      "[97]\ttraining's auc: 0.887253\ttraining's binary_logloss: 0.12194\tvalid_1's auc: 0.831265\tvalid_1's binary_logloss: 0.135908\n",
      "[98]\ttraining's auc: 0.88765\ttraining's binary_logloss: 0.121808\tvalid_1's auc: 0.831519\tvalid_1's binary_logloss: 0.135868\n",
      "[99]\ttraining's auc: 0.887879\ttraining's binary_logloss: 0.121691\tvalid_1's auc: 0.831455\tvalid_1's binary_logloss: 0.135854\n",
      "[100]\ttraining's auc: 0.888166\ttraining's binary_logloss: 0.121575\tvalid_1's auc: 0.83126\tvalid_1's binary_logloss: 0.135856\n",
      "[1]\ttraining's auc: 0.826374\ttraining's binary_logloss: 0.164747\tvalid_1's auc: 0.813652\tvalid_1's binary_logloss: 0.158892\n",
      "[2]\ttraining's auc: 0.828688\ttraining's binary_logloss: 0.16274\tvalid_1's auc: 0.814697\tvalid_1's binary_logloss: 0.157243\n",
      "[3]\ttraining's auc: 0.831453\ttraining's binary_logloss: 0.160948\tvalid_1's auc: 0.817983\tvalid_1's binary_logloss: 0.155679\n",
      "[4]\ttraining's auc: 0.832427\ttraining's binary_logloss: 0.159315\tvalid_1's auc: 0.818151\tvalid_1's binary_logloss: 0.154326\n",
      "[5]\ttraining's auc: 0.835396\ttraining's binary_logloss: 0.1578\tvalid_1's auc: 0.81967\tvalid_1's binary_logloss: 0.153072\n",
      "[6]\ttraining's auc: 0.838759\ttraining's binary_logloss: 0.156414\tvalid_1's auc: 0.821771\tvalid_1's binary_logloss: 0.15188\n",
      "[7]\ttraining's auc: 0.840479\ttraining's binary_logloss: 0.155141\tvalid_1's auc: 0.824454\tvalid_1's binary_logloss: 0.150827\n",
      "[8]\ttraining's auc: 0.84112\ttraining's binary_logloss: 0.153937\tvalid_1's auc: 0.824531\tvalid_1's binary_logloss: 0.149835\n",
      "[9]\ttraining's auc: 0.842056\ttraining's binary_logloss: 0.152806\tvalid_1's auc: 0.825335\tvalid_1's binary_logloss: 0.148909\n",
      "[10]\ttraining's auc: 0.843103\ttraining's binary_logloss: 0.15176\tvalid_1's auc: 0.825846\tvalid_1's binary_logloss: 0.148059\n",
      "[11]\ttraining's auc: 0.843774\ttraining's binary_logloss: 0.150786\tvalid_1's auc: 0.826224\tvalid_1's binary_logloss: 0.147257\n",
      "[12]\ttraining's auc: 0.847482\ttraining's binary_logloss: 0.149853\tvalid_1's auc: 0.829888\tvalid_1's binary_logloss: 0.146517\n",
      "[13]\ttraining's auc: 0.848602\ttraining's binary_logloss: 0.148991\tvalid_1's auc: 0.830007\tvalid_1's binary_logloss: 0.145819\n",
      "[14]\ttraining's auc: 0.84897\ttraining's binary_logloss: 0.148166\tvalid_1's auc: 0.829994\tvalid_1's binary_logloss: 0.145141\n",
      "[15]\ttraining's auc: 0.849639\ttraining's binary_logloss: 0.147361\tvalid_1's auc: 0.829923\tvalid_1's binary_logloss: 0.144546\n",
      "[16]\ttraining's auc: 0.850498\ttraining's binary_logloss: 0.146609\tvalid_1's auc: 0.829911\tvalid_1's binary_logloss: 0.143967\n",
      "[17]\ttraining's auc: 0.850791\ttraining's binary_logloss: 0.145901\tvalid_1's auc: 0.830165\tvalid_1's binary_logloss: 0.143422\n",
      "[18]\ttraining's auc: 0.852013\ttraining's binary_logloss: 0.145227\tvalid_1's auc: 0.830766\tvalid_1's binary_logloss: 0.1429\n",
      "[19]\ttraining's auc: 0.852539\ttraining's binary_logloss: 0.144539\tvalid_1's auc: 0.831139\tvalid_1's binary_logloss: 0.142401\n",
      "[20]\ttraining's auc: 0.853698\ttraining's binary_logloss: 0.143882\tvalid_1's auc: 0.831679\tvalid_1's binary_logloss: 0.14192\n",
      "[21]\ttraining's auc: 0.854376\ttraining's binary_logloss: 0.143259\tvalid_1's auc: 0.831805\tvalid_1's binary_logloss: 0.141432\n",
      "[22]\ttraining's auc: 0.854952\ttraining's binary_logloss: 0.142675\tvalid_1's auc: 0.832628\tvalid_1's binary_logloss: 0.140983\n",
      "[23]\ttraining's auc: 0.85535\ttraining's binary_logloss: 0.142115\tvalid_1's auc: 0.833283\tvalid_1's binary_logloss: 0.14055\n",
      "[24]\ttraining's auc: 0.856172\ttraining's binary_logloss: 0.141577\tvalid_1's auc: 0.83472\tvalid_1's binary_logloss: 0.140156\n",
      "[25]\ttraining's auc: 0.857059\ttraining's binary_logloss: 0.141052\tvalid_1's auc: 0.834676\tvalid_1's binary_logloss: 0.139798\n",
      "[26]\ttraining's auc: 0.857799\ttraining's binary_logloss: 0.14055\tvalid_1's auc: 0.834992\tvalid_1's binary_logloss: 0.139424\n",
      "[27]\ttraining's auc: 0.858112\ttraining's binary_logloss: 0.140053\tvalid_1's auc: 0.835325\tvalid_1's binary_logloss: 0.139036\n",
      "[28]\ttraining's auc: 0.858544\ttraining's binary_logloss: 0.13959\tvalid_1's auc: 0.835425\tvalid_1's binary_logloss: 0.138689\n",
      "[29]\ttraining's auc: 0.858888\ttraining's binary_logloss: 0.139137\tvalid_1's auc: 0.835662\tvalid_1's binary_logloss: 0.13837\n",
      "[30]\ttraining's auc: 0.859921\ttraining's binary_logloss: 0.138699\tvalid_1's auc: 0.83536\tvalid_1's binary_logloss: 0.138101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\ttraining's auc: 0.860346\ttraining's binary_logloss: 0.138259\tvalid_1's auc: 0.835652\tvalid_1's binary_logloss: 0.137767\n",
      "[32]\ttraining's auc: 0.860623\ttraining's binary_logloss: 0.137851\tvalid_1's auc: 0.835706\tvalid_1's binary_logloss: 0.137481\n",
      "[33]\ttraining's auc: 0.861233\ttraining's binary_logloss: 0.137451\tvalid_1's auc: 0.835552\tvalid_1's binary_logloss: 0.137215\n",
      "[34]\ttraining's auc: 0.861685\ttraining's binary_logloss: 0.137067\tvalid_1's auc: 0.835533\tvalid_1's binary_logloss: 0.136967\n",
      "[35]\ttraining's auc: 0.862184\ttraining's binary_logloss: 0.136698\tvalid_1's auc: 0.835406\tvalid_1's binary_logloss: 0.136728\n",
      "[36]\ttraining's auc: 0.862667\ttraining's binary_logloss: 0.136338\tvalid_1's auc: 0.835312\tvalid_1's binary_logloss: 0.136482\n",
      "[37]\ttraining's auc: 0.862991\ttraining's binary_logloss: 0.135983\tvalid_1's auc: 0.835197\tvalid_1's binary_logloss: 0.136257\n",
      "[38]\ttraining's auc: 0.863528\ttraining's binary_logloss: 0.135648\tvalid_1's auc: 0.835072\tvalid_1's binary_logloss: 0.136031\n",
      "[39]\ttraining's auc: 0.864036\ttraining's binary_logloss: 0.135331\tvalid_1's auc: 0.834926\tvalid_1's binary_logloss: 0.135828\n",
      "[40]\ttraining's auc: 0.86419\ttraining's binary_logloss: 0.135015\tvalid_1's auc: 0.834894\tvalid_1's binary_logloss: 0.135611\n",
      "[41]\ttraining's auc: 0.86474\ttraining's binary_logloss: 0.134713\tvalid_1's auc: 0.83485\tvalid_1's binary_logloss: 0.135404\n",
      "[42]\ttraining's auc: 0.865544\ttraining's binary_logloss: 0.134411\tvalid_1's auc: 0.834855\tvalid_1's binary_logloss: 0.135221\n",
      "[43]\ttraining's auc: 0.865918\ttraining's binary_logloss: 0.13411\tvalid_1's auc: 0.834771\tvalid_1's binary_logloss: 0.135063\n",
      "[44]\ttraining's auc: 0.866171\ttraining's binary_logloss: 0.13382\tvalid_1's auc: 0.834808\tvalid_1's binary_logloss: 0.134884\n",
      "[45]\ttraining's auc: 0.866869\ttraining's binary_logloss: 0.13354\tvalid_1's auc: 0.83508\tvalid_1's binary_logloss: 0.13471\n",
      "[46]\ttraining's auc: 0.86732\ttraining's binary_logloss: 0.133271\tvalid_1's auc: 0.835107\tvalid_1's binary_logloss: 0.134547\n",
      "[47]\ttraining's auc: 0.867708\ttraining's binary_logloss: 0.133008\tvalid_1's auc: 0.835387\tvalid_1's binary_logloss: 0.134399\n",
      "[48]\ttraining's auc: 0.86798\ttraining's binary_logloss: 0.132763\tvalid_1's auc: 0.835316\tvalid_1's binary_logloss: 0.13426\n",
      "[49]\ttraining's auc: 0.868314\ttraining's binary_logloss: 0.132505\tvalid_1's auc: 0.835349\tvalid_1's binary_logloss: 0.134127\n",
      "[50]\ttraining's auc: 0.868599\ttraining's binary_logloss: 0.132263\tvalid_1's auc: 0.835123\tvalid_1's binary_logloss: 0.134008\n",
      "[51]\ttraining's auc: 0.869004\ttraining's binary_logloss: 0.132025\tvalid_1's auc: 0.835034\tvalid_1's binary_logloss: 0.13389\n",
      "[52]\ttraining's auc: 0.869305\ttraining's binary_logloss: 0.131788\tvalid_1's auc: 0.83492\tvalid_1's binary_logloss: 0.133776\n",
      "[53]\ttraining's auc: 0.869633\ttraining's binary_logloss: 0.131559\tvalid_1's auc: 0.834772\tvalid_1's binary_logloss: 0.133668\n",
      "[54]\ttraining's auc: 0.870067\ttraining's binary_logloss: 0.131313\tvalid_1's auc: 0.834806\tvalid_1's binary_logloss: 0.13355\n",
      "[55]\ttraining's auc: 0.870349\ttraining's binary_logloss: 0.131103\tvalid_1's auc: 0.834867\tvalid_1's binary_logloss: 0.133439\n",
      "[56]\ttraining's auc: 0.870699\ttraining's binary_logloss: 0.130868\tvalid_1's auc: 0.834689\tvalid_1's binary_logloss: 0.133343\n",
      "[57]\ttraining's auc: 0.871007\ttraining's binary_logloss: 0.130664\tvalid_1's auc: 0.834627\tvalid_1's binary_logloss: 0.133228\n",
      "[58]\ttraining's auc: 0.871175\ttraining's binary_logloss: 0.130444\tvalid_1's auc: 0.834535\tvalid_1's binary_logloss: 0.13314\n",
      "[59]\ttraining's auc: 0.871393\ttraining's binary_logloss: 0.130238\tvalid_1's auc: 0.834511\tvalid_1's binary_logloss: 0.133048\n",
      "[60]\ttraining's auc: 0.871753\ttraining's binary_logloss: 0.130041\tvalid_1's auc: 0.834354\tvalid_1's binary_logloss: 0.132979\n",
      "[61]\ttraining's auc: 0.871933\ttraining's binary_logloss: 0.129849\tvalid_1's auc: 0.834247\tvalid_1's binary_logloss: 0.132898\n",
      "[62]\ttraining's auc: 0.87225\ttraining's binary_logloss: 0.129658\tvalid_1's auc: 0.834386\tvalid_1's binary_logloss: 0.132803\n",
      "[1]\ttraining's auc: 0.827078\ttraining's binary_logloss: 0.160957\tvalid_1's auc: 0.806826\tvalid_1's binary_logloss: 0.166539\n",
      "[2]\ttraining's auc: 0.829428\ttraining's binary_logloss: 0.159062\tvalid_1's auc: 0.81121\tvalid_1's binary_logloss: 0.1647\n",
      "[3]\ttraining's auc: 0.834189\ttraining's binary_logloss: 0.157388\tvalid_1's auc: 0.814212\tvalid_1's binary_logloss: 0.163126\n",
      "[4]\ttraining's auc: 0.834898\ttraining's binary_logloss: 0.15584\tvalid_1's auc: 0.816332\tvalid_1's binary_logloss: 0.161663\n",
      "[5]\ttraining's auc: 0.836613\ttraining's binary_logloss: 0.154385\tvalid_1's auc: 0.817578\tvalid_1's binary_logloss: 0.160308\n",
      "[6]\ttraining's auc: 0.837141\ttraining's binary_logloss: 0.153051\tvalid_1's auc: 0.817975\tvalid_1's binary_logloss: 0.159098\n",
      "[7]\ttraining's auc: 0.84037\ttraining's binary_logloss: 0.15182\tvalid_1's auc: 0.821337\tvalid_1's binary_logloss: 0.157941\n",
      "[8]\ttraining's auc: 0.841178\ttraining's binary_logloss: 0.150681\tvalid_1's auc: 0.821845\tvalid_1's binary_logloss: 0.156842\n",
      "[9]\ttraining's auc: 0.841712\ttraining's binary_logloss: 0.149623\tvalid_1's auc: 0.821699\tvalid_1's binary_logloss: 0.155891\n",
      "[10]\ttraining's auc: 0.843781\ttraining's binary_logloss: 0.148613\tvalid_1's auc: 0.824629\tvalid_1's binary_logloss: 0.154956\n",
      "[11]\ttraining's auc: 0.844314\ttraining's binary_logloss: 0.147655\tvalid_1's auc: 0.82506\tvalid_1's binary_logloss: 0.154081\n",
      "[12]\ttraining's auc: 0.845033\ttraining's binary_logloss: 0.146756\tvalid_1's auc: 0.825923\tvalid_1's binary_logloss: 0.15327\n",
      "[13]\ttraining's auc: 0.846456\ttraining's binary_logloss: 0.145885\tvalid_1's auc: 0.826616\tvalid_1's binary_logloss: 0.152506\n",
      "[14]\ttraining's auc: 0.847715\ttraining's binary_logloss: 0.145065\tvalid_1's auc: 0.827245\tvalid_1's binary_logloss: 0.151776\n",
      "[15]\ttraining's auc: 0.84848\ttraining's binary_logloss: 0.144288\tvalid_1's auc: 0.827591\tvalid_1's binary_logloss: 0.151073\n",
      "[16]\ttraining's auc: 0.848826\ttraining's binary_logloss: 0.143548\tvalid_1's auc: 0.827746\tvalid_1's binary_logloss: 0.150435\n",
      "[17]\ttraining's auc: 0.85013\ttraining's binary_logloss: 0.142811\tvalid_1's auc: 0.827822\tvalid_1's binary_logloss: 0.149836\n",
      "[18]\ttraining's auc: 0.850937\ttraining's binary_logloss: 0.142125\tvalid_1's auc: 0.828309\tvalid_1's binary_logloss: 0.149259\n",
      "[19]\ttraining's auc: 0.851384\ttraining's binary_logloss: 0.141468\tvalid_1's auc: 0.828536\tvalid_1's binary_logloss: 0.148697\n",
      "[20]\ttraining's auc: 0.852465\ttraining's binary_logloss: 0.140849\tvalid_1's auc: 0.829155\tvalid_1's binary_logloss: 0.148176\n",
      "[21]\ttraining's auc: 0.8531\ttraining's binary_logloss: 0.140262\tvalid_1's auc: 0.829788\tvalid_1's binary_logloss: 0.14768\n",
      "[22]\ttraining's auc: 0.853672\ttraining's binary_logloss: 0.139699\tvalid_1's auc: 0.829902\tvalid_1's binary_logloss: 0.147223\n",
      "[23]\ttraining's auc: 0.854069\ttraining's binary_logloss: 0.139153\tvalid_1's auc: 0.830179\tvalid_1's binary_logloss: 0.146752\n",
      "[24]\ttraining's auc: 0.854188\ttraining's binary_logloss: 0.138636\tvalid_1's auc: 0.830134\tvalid_1's binary_logloss: 0.146339\n",
      "[25]\ttraining's auc: 0.854513\ttraining's binary_logloss: 0.138145\tvalid_1's auc: 0.830101\tvalid_1's binary_logloss: 0.145959\n",
      "[26]\ttraining's auc: 0.855162\ttraining's binary_logloss: 0.13766\tvalid_1's auc: 0.830427\tvalid_1's binary_logloss: 0.145557\n",
      "[27]\ttraining's auc: 0.855745\ttraining's binary_logloss: 0.137201\tvalid_1's auc: 0.830493\tvalid_1's binary_logloss: 0.145197\n",
      "[28]\ttraining's auc: 0.856194\ttraining's binary_logloss: 0.136764\tvalid_1's auc: 0.830498\tvalid_1's binary_logloss: 0.144827\n",
      "[29]\ttraining's auc: 0.856409\ttraining's binary_logloss: 0.136291\tvalid_1's auc: 0.830549\tvalid_1's binary_logloss: 0.144485\n",
      "[30]\ttraining's auc: 0.856921\ttraining's binary_logloss: 0.135833\tvalid_1's auc: 0.831037\tvalid_1's binary_logloss: 0.144164\n",
      "[31]\ttraining's auc: 0.857352\ttraining's binary_logloss: 0.135401\tvalid_1's auc: 0.831342\tvalid_1's binary_logloss: 0.143854\n",
      "[32]\ttraining's auc: 0.857588\ttraining's binary_logloss: 0.134987\tvalid_1's auc: 0.831532\tvalid_1's binary_logloss: 0.143556\n",
      "[33]\ttraining's auc: 0.857821\ttraining's binary_logloss: 0.134603\tvalid_1's auc: 0.831764\tvalid_1's binary_logloss: 0.143283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34]\ttraining's auc: 0.858306\ttraining's binary_logloss: 0.13423\tvalid_1's auc: 0.831793\tvalid_1's binary_logloss: 0.143018\n",
      "[35]\ttraining's auc: 0.858929\ttraining's binary_logloss: 0.133883\tvalid_1's auc: 0.831932\tvalid_1's binary_logloss: 0.142746\n",
      "[36]\ttraining's auc: 0.859609\ttraining's binary_logloss: 0.133542\tvalid_1's auc: 0.832139\tvalid_1's binary_logloss: 0.142495\n",
      "[37]\ttraining's auc: 0.860114\ttraining's binary_logloss: 0.133199\tvalid_1's auc: 0.832296\tvalid_1's binary_logloss: 0.142265\n",
      "[38]\ttraining's auc: 0.860777\ttraining's binary_logloss: 0.132855\tvalid_1's auc: 0.832378\tvalid_1's binary_logloss: 0.142016\n",
      "[39]\ttraining's auc: 0.861056\ttraining's binary_logloss: 0.132533\tvalid_1's auc: 0.832541\tvalid_1's binary_logloss: 0.141797\n",
      "[40]\ttraining's auc: 0.861747\ttraining's binary_logloss: 0.132224\tvalid_1's auc: 0.832606\tvalid_1's binary_logloss: 0.141578\n",
      "[41]\ttraining's auc: 0.862158\ttraining's binary_logloss: 0.131929\tvalid_1's auc: 0.832747\tvalid_1's binary_logloss: 0.141381\n",
      "[42]\ttraining's auc: 0.862803\ttraining's binary_logloss: 0.131641\tvalid_1's auc: 0.8327\tvalid_1's binary_logloss: 0.141179\n",
      "[43]\ttraining's auc: 0.863343\ttraining's binary_logloss: 0.131354\tvalid_1's auc: 0.832837\tvalid_1's binary_logloss: 0.140985\n",
      "[44]\ttraining's auc: 0.86388\ttraining's binary_logloss: 0.131084\tvalid_1's auc: 0.832996\tvalid_1's binary_logloss: 0.14079\n",
      "[45]\ttraining's auc: 0.864446\ttraining's binary_logloss: 0.130812\tvalid_1's auc: 0.833038\tvalid_1's binary_logloss: 0.140619\n",
      "[46]\ttraining's auc: 0.864811\ttraining's binary_logloss: 0.130549\tvalid_1's auc: 0.83316\tvalid_1's binary_logloss: 0.140456\n",
      "[47]\ttraining's auc: 0.865352\ttraining's binary_logloss: 0.130289\tvalid_1's auc: 0.833126\tvalid_1's binary_logloss: 0.140285\n",
      "[48]\ttraining's auc: 0.865811\ttraining's binary_logloss: 0.130038\tvalid_1's auc: 0.833192\tvalid_1's binary_logloss: 0.140136\n",
      "[49]\ttraining's auc: 0.866929\ttraining's binary_logloss: 0.129784\tvalid_1's auc: 0.833911\tvalid_1's binary_logloss: 0.139972\n",
      "[50]\ttraining's auc: 0.867961\ttraining's binary_logloss: 0.129522\tvalid_1's auc: 0.835037\tvalid_1's binary_logloss: 0.139818\n",
      "[51]\ttraining's auc: 0.868287\ttraining's binary_logloss: 0.129291\tvalid_1's auc: 0.835004\tvalid_1's binary_logloss: 0.139683\n",
      "[52]\ttraining's auc: 0.868959\ttraining's binary_logloss: 0.12906\tvalid_1's auc: 0.835063\tvalid_1's binary_logloss: 0.139545\n",
      "[53]\ttraining's auc: 0.869297\ttraining's binary_logloss: 0.128834\tvalid_1's auc: 0.83522\tvalid_1's binary_logloss: 0.139393\n",
      "[54]\ttraining's auc: 0.86977\ttraining's binary_logloss: 0.128611\tvalid_1's auc: 0.835131\tvalid_1's binary_logloss: 0.139274\n",
      "[55]\ttraining's auc: 0.870365\ttraining's binary_logloss: 0.128388\tvalid_1's auc: 0.835251\tvalid_1's binary_logloss: 0.139136\n",
      "[56]\ttraining's auc: 0.870909\ttraining's binary_logloss: 0.12817\tvalid_1's auc: 0.835378\tvalid_1's binary_logloss: 0.139008\n",
      "[57]\ttraining's auc: 0.871175\ttraining's binary_logloss: 0.127966\tvalid_1's auc: 0.835592\tvalid_1's binary_logloss: 0.138884\n",
      "[58]\ttraining's auc: 0.871624\ttraining's binary_logloss: 0.127769\tvalid_1's auc: 0.835808\tvalid_1's binary_logloss: 0.138778\n",
      "[59]\ttraining's auc: 0.872034\ttraining's binary_logloss: 0.127565\tvalid_1's auc: 0.835826\tvalid_1's binary_logloss: 0.138651\n",
      "[60]\ttraining's auc: 0.873075\ttraining's binary_logloss: 0.127338\tvalid_1's auc: 0.836086\tvalid_1's binary_logloss: 0.138544\n",
      "[61]\ttraining's auc: 0.87342\ttraining's binary_logloss: 0.127152\tvalid_1's auc: 0.836126\tvalid_1's binary_logloss: 0.13845\n",
      "[62]\ttraining's auc: 0.873704\ttraining's binary_logloss: 0.126967\tvalid_1's auc: 0.836205\tvalid_1's binary_logloss: 0.138346\n",
      "[63]\ttraining's auc: 0.874207\ttraining's binary_logloss: 0.126763\tvalid_1's auc: 0.836345\tvalid_1's binary_logloss: 0.138249\n",
      "[64]\ttraining's auc: 0.874564\ttraining's binary_logloss: 0.126593\tvalid_1's auc: 0.836528\tvalid_1's binary_logloss: 0.138159\n",
      "[65]\ttraining's auc: 0.874693\ttraining's binary_logloss: 0.126423\tvalid_1's auc: 0.836587\tvalid_1's binary_logloss: 0.138066\n",
      "[66]\ttraining's auc: 0.875095\ttraining's binary_logloss: 0.126263\tvalid_1's auc: 0.836868\tvalid_1's binary_logloss: 0.137982\n",
      "[67]\ttraining's auc: 0.875326\ttraining's binary_logloss: 0.126102\tvalid_1's auc: 0.837139\tvalid_1's binary_logloss: 0.13789\n",
      "[68]\ttraining's auc: 0.875758\ttraining's binary_logloss: 0.125918\tvalid_1's auc: 0.837392\tvalid_1's binary_logloss: 0.137816\n",
      "[69]\ttraining's auc: 0.876135\ttraining's binary_logloss: 0.125733\tvalid_1's auc: 0.837368\tvalid_1's binary_logloss: 0.137746\n",
      "[70]\ttraining's auc: 0.876375\ttraining's binary_logloss: 0.125567\tvalid_1's auc: 0.83736\tvalid_1's binary_logloss: 0.13766\n",
      "[71]\ttraining's auc: 0.876895\ttraining's binary_logloss: 0.125405\tvalid_1's auc: 0.837383\tvalid_1's binary_logloss: 0.137575\n",
      "[72]\ttraining's auc: 0.877208\ttraining's binary_logloss: 0.125249\tvalid_1's auc: 0.837341\tvalid_1's binary_logloss: 0.137503\n",
      "[73]\ttraining's auc: 0.877587\ttraining's binary_logloss: 0.125085\tvalid_1's auc: 0.837398\tvalid_1's binary_logloss: 0.137443\n",
      "[74]\ttraining's auc: 0.877803\ttraining's binary_logloss: 0.12494\tvalid_1's auc: 0.837351\tvalid_1's binary_logloss: 0.13737\n",
      "[75]\ttraining's auc: 0.878086\ttraining's binary_logloss: 0.124777\tvalid_1's auc: 0.837364\tvalid_1's binary_logloss: 0.137315\n",
      "[76]\ttraining's auc: 0.878504\ttraining's binary_logloss: 0.124619\tvalid_1's auc: 0.837236\tvalid_1's binary_logloss: 0.137259\n",
      "[77]\ttraining's auc: 0.878911\ttraining's binary_logloss: 0.124471\tvalid_1's auc: 0.837336\tvalid_1's binary_logloss: 0.137193\n",
      "[78]\ttraining's auc: 0.879287\ttraining's binary_logloss: 0.124321\tvalid_1's auc: 0.837223\tvalid_1's binary_logloss: 0.137143\n",
      "[79]\ttraining's auc: 0.879658\ttraining's binary_logloss: 0.124175\tvalid_1's auc: 0.837299\tvalid_1's binary_logloss: 0.137086\n",
      "[80]\ttraining's auc: 0.879888\ttraining's binary_logloss: 0.124032\tvalid_1's auc: 0.837402\tvalid_1's binary_logloss: 0.137026\n",
      "[81]\ttraining's auc: 0.880091\ttraining's binary_logloss: 0.123891\tvalid_1's auc: 0.837435\tvalid_1's binary_logloss: 0.136979\n",
      "[82]\ttraining's auc: 0.880479\ttraining's binary_logloss: 0.123738\tvalid_1's auc: 0.837332\tvalid_1's binary_logloss: 0.136947\n",
      "[83]\ttraining's auc: 0.88089\ttraining's binary_logloss: 0.123584\tvalid_1's auc: 0.837385\tvalid_1's binary_logloss: 0.136898\n",
      "[84]\ttraining's auc: 0.881134\ttraining's binary_logloss: 0.12344\tvalid_1's auc: 0.837391\tvalid_1's binary_logloss: 0.136853\n",
      "[85]\ttraining's auc: 0.881432\ttraining's binary_logloss: 0.123298\tvalid_1's auc: 0.837403\tvalid_1's binary_logloss: 0.136817\n",
      "  0%|                                                                           | 0/50 [00:17<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1332/2372077942.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m best = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# 최대 반복 횟수를 지정합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             trials=trials, rstate=np.random.default_rng(seed=30))\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fmin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m         return trials.fmin(\n\u001b[0m\u001b[0;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         return fmin(\n\u001b[0m\u001b[0;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    298\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             )\n\u001b[1;32m--> 892\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1332/2572885391.py\u001b[0m in \u001b[0;36mobjective_func\u001b[1;34m(search_space)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric=\"auc\",\n\u001b[0m\u001b[0;32m     20\u001b[0m            eval_set=[(X_tr, y_tr), (X_val, y_val)])\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    965\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[0;32m    968\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   3019\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3020\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3021\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출. \n",
    "best = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials, rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88959cef",
   "metadata": {},
   "source": [
    "도출된 최적 하이퍼 파라미터를 이용하여 LightGBM을 학습 후에 테스트 데이터 세트에서 ROC-AUC를 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de46b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf =  LGBMClassifier(n_estimators=500, num_leaves=int(best['num_leaves']),\n",
    "                           max_depth=int(best['max_depth']),\n",
    "                           min_child_samples=int(best['min_child_samples']), \n",
    "                           subsample=round(best['subsample'], 5),\n",
    "                           learning_rate=round(best['learning_rate'], 5)\n",
    "                          )\n",
    "\n",
    "# evaluation metric을 auc로, early stopping은 100 으로 설정하고 학습 수행. \n",
    "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100, \n",
    "            eval_metric=\"auc\",eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
