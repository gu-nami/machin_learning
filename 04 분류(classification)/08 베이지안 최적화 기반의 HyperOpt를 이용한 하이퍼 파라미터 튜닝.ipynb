{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cba25e8",
   "metadata": {},
   "source": [
    "## 08 베이지안 최적화 기반의 HyperOpt를 이용한 하이퍼 파라미터 튜닝\n",
    "\n",
    "Grid Search 방식의 단점 : 튜닝해야 할 하이퍼 파라미터 개수가 많을 경우 최적화 수행 시간이 오래 걸린다. 개별 하이퍼 파라미터 값의 범위가 넓거나 학습 데이터가 대용량일 경우에는 최적화 시간이 더욱 늘어나게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d7f4e",
   "metadata": {},
   "source": [
    "XGBoost나 LightGBM은 다른 알고리즘에 비해 많은 개수의 하이퍼 파라미터를 가지고 있다. 때문에 실무의 대용량 학습 데이터에 Grid Search 방식으로 최적 하이퍼 파라미터를 찾으려면 많은 시간이 소모될 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66685b37",
   "metadata": {},
   "source": [
    "예시 ) LightGBM의 6가지 하이퍼 파라미터를 최적화하려고 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ec500",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "'max_depth' = [10, 20, 30, 40, 50], 'num_leaves' = [35, 45, 55, 65],\n",
    "'colsample_bytree' = [0.5, 0.6, 0.7, 0.8, 0.9], 'subsample' = [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "'min_child_weight' = [10, 20, 30, 40], reg_alpha = [0.01, 0.05, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7842dc",
   "metadata": {},
   "source": [
    "이 경우 Grid Search 방식은 5×4×5×5×4×3 = 6000회에 걸쳐서 반복적으로 학습과 평가를 수행해야만 하기에 수행 시간이 매우 오래 걸릴 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472c7646",
   "metadata": {},
   "source": [
    "때문에 실무의 대용량 학습 데이터에 XGBoost나 LightGBM의 하이퍼 파라미터 튜닝 시에 Grid Search 방식보다는 다른 방식을 적용하곤 하는데 대표적으로 베지안 최적화 기법을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff6cf6f",
   "metadata": {},
   "source": [
    "#### 베이지안 최적화 개요\n",
    "\n",
    "베이지안 최적화는 목적 함수 식을 제대로 알 수 없는 블랙 박스 형태의 함수에서 최대 또는 최소 함수 반환 값을 만드는 최적 입력값을 가능한 적은 시도를 통해 빠르고 효과적으로 찾아주는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97612f7c",
   "metadata": {},
   "source": [
    "베이지안 최적화는 이름에서 알 수 있듯이 베이지안 확류에 기반을 두고 있는 최적화 기법이다. 베이지안 확률이 새로운 사건의 관측이나 새로운 샘플 데이터를 기반으로 사후 확률을 개선해 나가듯이, 베이지안 최적화는 새로운 데이터를 입력받았을 때 최적 함수를 예측하는 사후 모델을 개선해 나가면서 최적 함수 모델을 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c73a38",
   "metadata": {},
   "source": [
    "베이지안 최적화를 구성하는 두 가지 중요 요소는 대체 모델(Surrogate Model)과 획득 함수(Acquisition Function)이다.\n",
    "\n",
    "대체 모델은 획득 함수가 계산한 하이퍼 파라미터를 입력받으면서 점차적으로 개선되며, 개선된 대체 모델을 기반으로 획득 함수는 더 정확한 하이퍼 파라미터를 계산할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302dba7f",
   "metadata": {},
   "source": [
    "__베이지안 최적화 과정__\n",
    "\n",
    "+ step 1 : 최초에는 랜덤하게 하이퍼 파라미터들을 샘플링하고 성능 결과를 관측한다. 아래 그림에서 검은색 원은 특정 하이퍼 파라미터가 입력되었을 때 관측된 성능 지표 결괏값을 뜻하며 주황색 사선은 찾아야 할 목표 최적함수이다.\n",
    "\n",
    "&nbsp;\n",
    " \n",
    "+ step 2 : 관측된 값을 기반으로 대체 모델은 최적 함수를 추정한다. 아래 그림에서 파란색 실선은 대체 모델이 추정한 최적 함수이다. 아래 그림에서 파란색 실선은 대체 모델이 추정한 최적 함수이다. 옅은 파란색으로 되어 있는 영역은 예측된 함수의 신뢰 구간이다. 추정된 함수의 결괏값 오류 편차를 의미하며 추정 함수의 불확실성을 나타낸다. 최적 관측값은 y축 value에서 가장 높은 값을 가질 때의 하이퍼 파라미터이다.\n",
    "\n",
    "&nbsp;\n",
    " \n",
    "+ setp 3 : 추정된 최적 함수를 기반으로 획득 함수(Acquisition Function)는 다음으로 관측할 하이퍼 파라미터 값을 계산한다. 획득 함수는 이전의 최적 관측값보다 더 큰 최댓값을 가질 가능성이 높은 지점을 찾아서 다음에 관측할 하이퍼 파라미터를 대체 모델에 전달한다.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "+ step 4 : 획득 함수로부터 전달된 하이퍼 파라미터를 수행하여 관측된 값을 기반으로 대체 모델은 갱신되어 다시 최적 함수를 예측 추정한다.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "이런 방식으로 step3과 step 4를 특정 횟수만큼 반복하게 되면 대체 모델의 불확실성이 개선되고 점차 정확한 최적 함수 추정이 가능하게 된다.\n",
    "\n",
    "대체 모델은 최적 함수를 추정할 때 다양한 알고리즘을 사용할 수 있는데 일반적으로는 가우시안 프로세스(Gaussian Process)를 적용한다. 하지만 뒤에 나올 HyperOpt는 가우시안 프로세스가 아닌 트리 파르젠 Estimator(TPE, Tree-structure Parzen Estimator)를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aefc21",
   "metadata": {},
   "source": [
    "### HyperOpt  사용하기\n",
    "\n",
    "HyperOpt, Bayesian Optimization, Optuna 등의 파이썬 패키지를 사용하여 베이지안 최적화를 머신러닝 모델의 하이퍼 파라미터 튜닝에 적용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d97b0",
   "metadata": {},
   "source": [
    "__HyperOpt 설치__\n",
    "\n",
    "명령 프롬프트에 `pip install hyperopt` 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c3e0f",
   "metadata": {},
   "source": [
    "__HyperOpt를 활용하는 주요 로직__\n",
    "\n",
    "+ 첫째는 입력 변수명과 입력값의 검색 공간(Search Space) 설정이다.\n",
    "\n",
    "+ 둘째는 목적 함수(Objective Function)의 설정이다.\n",
    "\n",
    "+ 마지막으로 `목적 함수의 반환 최솟값을 가지는 최적 입력값을 유추`하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5369ecf9",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "__HyperOpt의 hp 모듈을 이용하여 입력 변수명과 입력값의 검색 공간 설정하기__\n",
    "\n",
    "입력 변수명과 입력값 검색 공간은 파이썬 딕셔너리 형태로 설정되어야 하며, 키(key)값으로 입력 변수명, 밸류(value)값으로 해당 입력 변수의 검색 공간이 주어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "634945c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# -10 ~ 10까지 1간격을 가지는 입력 변수 x와 -15~15까지 1간격으로 입력 변수 y 설정\n",
    "search_space = {'x' : hp.quniform('x', -10, 10, 1), 'y' : hp.quniform('y', -15, 15, 1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62da0a0",
   "metadata": {},
   "source": [
    "hp 모듈은 입력값의 검색 공간을 다양하게 설정할 수 있도록 여러 가지 함수를 제공한다.\n",
    "\n",
    "+ hp.quniform(label, low, high, q) : label로 지정된 입력값 변수 검색 공간을 최솟값 low에서 최댓값 high까지 q의 간격을 가지고 설정\n",
    "\n",
    "+ hp.uniform(label, low, high) : 최솟값 low에서 최댓값 high까지 정규 분포 형태의 검색 공간 설정\n",
    "\n",
    "+ hp.randint(label, upper) : 0 부터 최댓값 upper까지 random한 정숫값으로 검색 공간 설정.\n",
    "\n",
    "+ hp.loguniform(label, low, high) : exp(uniform(low, high)) 값을 반환하며, 반환 값의 log 변환 된 값은 정규 분포 형태를 가지는 검색 공간 설정\n",
    "\n",
    "+ hp.choice(label, options) : 검색 값이 문자열 또는 문자열과 숫자값이 섞여 있을 경우 설정. Options는 리스트나 튜플 형태로 제공되며 hp.choice('tree_criterion', ['gini', 'entropy'])과 같이 설정하면 입력 변수 tree_criterion의 값을 'gini'와 'entropy'로 설정하여 입력함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb1c75",
   "metadata": {},
   "source": [
    "__목적 함수 생성__\n",
    "\n",
    "목적 함수는 반드시 변숫값과 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정 값을 반환하는 구조로 만들어져야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd0a04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# 목적 함수를 생성, 변숫값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "    \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db86cec6",
   "metadata": {},
   "source": [
    "위 코드는 search_space로 지정된 딕셔너리에서 x 입력 변숫값과 y 입력 변숫값을 추출하여 retval = x²- 20y로 계산된 값을 반환한다. 목적 함수의 반환값은 숫자형 단일값 외에도 딕셔너리 형태로 반환할 수 있다. 딕셔너리 형태로 반환할 경우에는 {'loss':retval, 'status':STATUS_OK}와 같이 loss와 status 키 값을 설정해서 반환해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3998451",
   "metadata": {},
   "source": [
    "입력값의 검색 공간과 목적 함수를 설정했으면 목적 함수의 반환값이 최소가 될 수 있는 최적의 입력값을 베이지안 최적화 기법에 기반하여 찾아 줘야 한다. HyperOpt는 이러한 기능을 수행할 수 있도록 fmin(objective, space, algo, max_evals, trials) 함수를 제공한다. fmin() 함수의 주요 인자는 아래와 같다.\n",
    "\n",
    "+ fn : 위에서 생성한 objective_func와 같은 목적 함수이다.\n",
    "\n",
    "+ space : 위에서 생성한 search_space와 같은 검색 공간 딕셔너리이다.\n",
    "\n",
    "+ algo : 베이지안 최적화 적용 알고리즘이다. 기본적으로 tpe.suggest이며 이는 HyperOpt의 기본 최적화 알고리즘인 TPE(Tree of Parzen Estimatr)를 의미한다.\n",
    "\n",
    "+ max_evals : 최적 입력값을 찾기 위해 시도한 입력값 및 해당 입력값의 목적 함수 반환값 결과를 저장하는 데 사용된다. Trials 클래스를 객체로 생성한 변수명을 입력한다.\n",
    "\n",
    "+ rstate : fmin()을 수행할 때마다 동일한 결괏값을 가질 수 있도록 설정하는 랜덤 시드(seed) 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37104727",
   "metadata": {},
   "source": [
    "__위에서 설정한 검색 공간인 search_space에서 목적 함수 object_func의 최솟값을 반환하는 최적 입력 변숫값을 찾을 수 있도록 베이지안 최적화 수행__\n",
    "\n",
    "HyperOpt의 fmin() 함수를 호출하되, 먼저 5번의 입력값 시도로 찾아낼 수 있도록 max_evals 인자 값으로 5를 설정\n",
    "\n",
    "목적 함수인 fn 인자로는 objective_func를, 검색 공간 인자인 space에는 search_space를, 최적화 적용 알고리즘 algo 인자는 기본값인 tpe.suggest로 설정\n",
    "\n",
    "또한 trials 인자값으로는 Trials() 객체를, 그리고 rstate의 경우는 임의의 랜덤 시드값을 입력\n",
    "\n",
    "일반적으로는 rstate를 잘 적용하지 않으며 HyperOpt는 rstate에 넣어주는 인자값으로 일반적인 정수형 값을 넣지 않는다. 또한 버전별로 rstate 인자값이 조금씩 다르다. 0.2.7버전에서는 넘파이의 random Generator를 생성하는 random.default_rng() 함수 인자로 seed값을 입력하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b29469b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 238.69trial/s, best loss: -224.0]\n",
      "best:  {'x': -4.0, 'y': 12.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "import numpy as np\n",
    "\n",
    "# 입력 결괏값을 저장한 Trials 객체값 생성\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변숫값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5, \n",
    "               trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "\n",
    "print('best: ', best_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc937ad",
   "metadata": {},
   "source": [
    "입력 변수 x의 공간 -10 ~10, y의 공간 -15 ~15에서 목적 함수의 반환 값을 x²- 20y로 설정했으므로 x는 0에 가까울수록 y는 15에 가까울수록 반환값이 최소로 근사될 수 있다. 확실하게 만족할 수준의 최적 x와 y값을 찾은 것은 아니지만, 5번의 수행으로 어느 정도 최적값에 다가설 수 있었다는 점을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0a527",
   "metadata": {},
   "source": [
    "__max_evals 값을 20으로 설정하여 20번의 수행으로 어떤 최적값을 반환하는지 살펴보기__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "849fb6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 232.55trial/s, best loss: -296.0]\n",
      "best:  {'x': 2.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "# max_evals 를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20,\n",
    "               trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "\n",
    "print('best: ', best_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26c8b8",
   "metadata": {},
   "source": [
    "20회 반복시 x는 2로, y는 15로 목적 함수의 최적 최솟값을 근사할 수 있는 결과를 도출했다. \n",
    "\n",
    "완벽한 정답인 x=0은 도출하지 못했지만, 입력값 x가 -10 ~ 10까지 21개의 경우의 수, 입력값 y가 -15~15까지 31개의 경우의 수를 가질 수 있기에, 만일 그리드 서치와 같이 순차적으로 x,y 변숫값을 입력해서 최소 함수 반환값을 찾는다면 최대 21*31=651회의 반복이 필요할 수도 있는데 반해서, 베이지안 최적화를 이용해서는 20회의 반복만으로 일정 수준의 최적값을 근사해 낼 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8df2ca",
   "metadata": {},
   "source": [
    "__fmin() 함수 수행 시 인자로 들어가는 Trials 객체의 중요 속성 results 와 value__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617c370",
   "metadata": {},
   "source": [
    "+ results 속성 : 함수의 반복 수행 시마다 반환되는 반환값을 가진다. 파이썬 리스트 형태이며 리스트 내의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값}과 같은 딕셔너리로 가지고 있다. \n",
    "\n",
    "+ value 속성 : 함수의 반복 수행 시마다 입력되는 입력 변숫값을 가진다. 딕셔너리 형태로 값을 가진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed1699bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': -64.0, 'status': 'ok'}, {'loss': -184.0, 'status': 'ok'}, {'loss': 56.0, 'status': 'ok'}, {'loss': -224.0, 'status': 'ok'}, {'loss': 61.0, 'status': 'ok'}, {'loss': -296.0, 'status': 'ok'}, {'loss': -40.0, 'status': 'ok'}, {'loss': 281.0, 'status': 'ok'}, {'loss': 64.0, 'status': 'ok'}, {'loss': 100.0, 'status': 'ok'}, {'loss': 60.0, 'status': 'ok'}, {'loss': -39.0, 'status': 'ok'}, {'loss': 1.0, 'status': 'ok'}, {'loss': -164.0, 'status': 'ok'}, {'loss': 21.0, 'status': 'ok'}, {'loss': -56.0, 'status': 'ok'}, {'loss': 284.0, 'status': 'ok'}, {'loss': 176.0, 'status': 'ok'}, {'loss': -171.0, 'status': 'ok'}, {'loss': 0.0, 'status': 'ok'}]\n"
     ]
    }
   ],
   "source": [
    "# fmin()에 인자로 들어가는 Trials 객체의 result 속성에 파이썬 리스트로 목적 함수 반환값들이 저장됨\n",
    "# 리스트 내부의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값}와 같은 딕셔너리임.\n",
    "print(trial_val.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a85ff2",
   "metadata": {},
   "source": [
    "max_evals=20으로 fmin() 함수는 20회의 반복 수행을 했으므로 results 속성은 loss와 status를 키값으로 ㄱ자니느 20개의 딕셔너리를 개별 원소를 가지는 리스트로 구성되어 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "248f8ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [-6.0, -4.0, 4.0, -4.0, 9.0, 2.0, 10.0, -9.0, -8.0, -0.0, -0.0, 1.0, 9.0, 6.0, 9.0, 2.0, -2.0, -4.0, 7.0, -0.0], 'y': [5.0, 10.0, -2.0, 12.0, 1.0, 15.0, 7.0, -10.0, 0.0, -5.0, -3.0, 2.0, 4.0, 10.0, 3.0, 3.0, -14.0, -8.0, 11.0, -0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Trials 객체의 vals 속성에 {'입력변수명':개별 수행 시마다 입력된 값 리스트} 형태로 저장됨.\n",
    "print(trial_val.vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7941d",
   "metadata": {},
   "source": [
    "vals는 딕셔너리 형태의 값을 가지며, 입력 변수 x와 y를 키값으로 가지며, x와 y키 값의 밸류는 20회의 반복 수행 시마다 사용되는 입력값들을 리스트 형태로 가지고 있는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "507ab719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y  losses\n",
       "0   -6.0   5.0   -64.0\n",
       "1   -4.0  10.0  -184.0\n",
       "2    4.0  -2.0    56.0\n",
       "3   -4.0  12.0  -224.0\n",
       "4    9.0   1.0    61.0\n",
       "5    2.0  15.0  -296.0\n",
       "6   10.0   7.0   -40.0\n",
       "7   -9.0 -10.0   281.0\n",
       "8   -8.0   0.0    64.0\n",
       "9   -0.0  -5.0   100.0\n",
       "10  -0.0  -3.0    60.0\n",
       "11   1.0   2.0   -39.0\n",
       "12   9.0   4.0     1.0\n",
       "13   6.0  10.0  -164.0\n",
       "14   9.0   3.0    21.0\n",
       "15   2.0   3.0   -56.0\n",
       "16  -2.0 -14.0   284.0\n",
       "17  -4.0  -8.0   176.0\n",
       "18   7.0  11.0  -171.0\n",
       "19  -0.0  -0.0     0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results와 vals 속성값들을 DataFrame으로 만들어 직관적으로 보기\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# results에서 loss 키값에 해당하는 밸류들을 추출하여 list로 생성. \n",
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "\n",
    "# DataFrame으로 생성.\n",
    "result_df = pd.DataFrame({'x': trial_val.vals['x'], 'y': trial_val.vals['y'], 'losses': losses})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d8d145",
   "metadata": {},
   "source": [
    "### HyperOpt를 이용한 XGBoost 하이퍼 파라미터 최적화\n",
    "\n",
    "적용해야 할 하이퍼 파라미터와 검색 공간을 설정하고, 목적 함수에서 XGBoost를 학습 후에 예측 성능 결과를 반환 값으로 설정한다. 그리고 fmin() 함수에서 목적 함수를 하이퍼 파라미터 검색 공간의 입력값들을 사용하여 최적의 예측 성능 결과를 반환하는 최적 입력값들을 결정하는 것이다. \n",
    "\n",
    "+ 주의 할 점\n",
    "\n",
    "특정 하이퍼 파라미터들은 정숫값만 이력을 받는데 HyperOpt는 입력값과 반환 값이 모두 실수형이기 대문에 하이퍼 파라미터 입력 시 형변환을 해줘야 하는 부분, 그리고 HyperOpt의 목적 함수는 최솟값을 반환할 수 있도록 최적화해야 하기 때문에 성능 값이 클수록 좋은 성능 지표일 경우 -1을 곱해줘야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40bebf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위스콘신 유방암 데이터 세트 로드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)\n",
    "cancer_df['target']= dataset.target\n",
    "X_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e5d6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label, test_size=0.2, random_state=156 )\n",
    "\n",
    "# 앞에서 추출한 학습 데이터를 다시 학습과 검증 데이터로 분리\n",
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, y_train, test_size=0.1, random_state=156 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2dc08",
   "metadata": {},
   "source": [
    "__하이퍼 파라미터와 검색공간 설정__\n",
    "\n",
    "max_depth는 5에서 20까지 1간격으로 (정수형 하이퍼 파라미터 이므로 hp.quniform() 사용 )\n",
    "\n",
    "min_child_weight는 1에서 2까지 1간격으로 (정수형 하이퍼 파라미터 이므로 hp.quniform() 사용 )\n",
    "\n",
    "learning_rate는 0.01에서 0.2사이 정규 분포된 값으로 (hp.uniform() 사용)\n",
    "\n",
    "colsample_bytree는 0.5에서 1사이 정규 분포된 값으로 하이퍼 파라미터 검색 공간을 설정  (hp.uniform() 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07c563b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 20까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2 사이 정규 분포된 값으로 검색.\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b49bb0",
   "metadata": {},
   "source": [
    "__목적 함수 설정하기__\n",
    "\n",
    "하이퍼 파라미터 튜닝을 위한 목적 함수는 검색 공간에서 설정한 하이퍼 파라미터들을 입력받아서 XGBoost를 학습하고 평가지표를 반환할 수 있도록 구성한다.\n",
    "\n",
    "+ 유의 사항\n",
    "\n",
    "1. 검색 공간에서 목적 함수로 입력되는 모든 인자들은 실수형 값이므로 이들을 XGBoostClassifier의 정수형 하이퍼 파라미터값으로 설정할 때는 정수형으로 형변환을 해야 한다. 즉, XGBoostClassifier(max_depth=int(search_space['max_depth'])) 같이 정수형 값으로 형변환을 해서 하이퍼 파라미터로 입력해 주어야 한다.\n",
    "\n",
    "2. HyperOpt의 목적함수는 최솟값을 반환할 수 있도록 최적화해야 하기 때문에 정확도와 같이 값이 클수록 좋은 성능 지표일 경우 -1을 곱한 뒤 반환하여, 더 큰 성능 지표가 더 작은 반환값이 되도록 만들어 줘야 한다. MAE,RMSE와 같은 지표는 작을수록 좋기 때문에 반환 시 -1을 곱해줄 필요가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a2c22",
   "metadata": {},
   "source": [
    "목적 함수인 objective_func() 정의\n",
    "\n",
    "목적 함수의 반환값은 교차 검증 기반의 평균 정확도(accuracy)를 사용한다. 3개의 교차 검증 세트로 정확도를 반환할 수 있도록 cross_val_score()를 적용하며, 수행 시간을 줄이기 위해서 n_estimators는 100으로 제한한다. cross_val_score()를 XGBoost나 LightGBM에 적용할 경우 조기 중단(early stopping)이 지원되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50c1c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "# fmin()에서 입력된 search_space 값으로 입력된 모든 값은 실수형임.\n",
    "# XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함.\n",
    "# 정확도는 높을수록 더 좋은 수치임. -1 * 정확도를 곱해서 큰 정확도 값일수록 최소가 되도록 변환\n",
    "def objective_func(search_space):\n",
    "    # 수행 시간 절약을 위해 nestimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            eval_metric='logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3)\n",
    "    \n",
    "    # accuracy는 cv=3 개수만큼 roc-auc 결과를 리스트로 가짐. 이를 평균해서 반환하되 -1을 곱함.\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0c71c",
   "metadata": {},
   "source": [
    "__fmin()을 이용해 최적 하이퍼 파라미터를 도출하기__\n",
    "\n",
    "최대 반복 수행 횟수 max_evals는 50회 지정하고 앞에서 설정한 목적함수 objective_func, 하이퍼 파라미터 검색공간 xgb_search_space 등을 인자로 입력한다. 동일한 실습결과를 도출하기 위해 rstate는 np.random.de-fault_rng(seed=9))로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8895c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [00:27<00:00,  1.80trial/s, best loss: -0.9670616939700244]\n",
      "best: {'colsample_bytree': 0.5424149213362504, 'learning_rate': 0.12601372924444681, 'max_depth': 17.0, 'min_child_weight': 2.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a4a91",
   "metadata": {},
   "source": [
    "정수형 하이퍼 파라미터인 max_depth, min_child_weight가 실수형 값으로 도출되었음을 유의\n",
    "\n",
    "__fmin()으로 추출된 최적 하이퍼 파라미터를 직접 XGBClassifier에 인자로 입력하기 전에 정수형 하이퍼 파라미터는 정수형으로 형 변환을, 실수형 하이퍼 파라미터는 소수점 5자리까지만 변환 후 확인__해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aef9433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colsample_bytree:0.54241, learning_rate:0.12601, max_depth:17, min_child_weight:2\n"
     ]
    }
   ],
   "source": [
    "print('colsample_bytree:{0}, learning_rate:{1}, max_depth:{2}, min_child_weight:{3}'.format(\n",
    "    round(best['colsample_bytree'], 5), round(best['learning_rate'], 5),\n",
    "    int(best['max_depth']), int(best['min_child_weight'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b287f31c",
   "metadata": {},
   "source": [
    "__된 최적 하이퍼 파라미터들을 이용해서 XGBClassifier를 재학습한 후 성능 평가 결과를 확인하기__\n",
    "\n",
    "XGBoost의 조기 중단을 검증 데이터 세트로 활용하며 n_estimators는 4000으로 증가시킨다. get_clf_eval()을 이용해 성능 평가를 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45a9d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "436edf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.58942\tvalidation_1-logloss:0.62048\n",
      "[1]\tvalidation_0-logloss:0.50801\tvalidation_1-logloss:0.55913\n",
      "[2]\tvalidation_0-logloss:0.44160\tvalidation_1-logloss:0.50928\n",
      "[3]\tvalidation_0-logloss:0.38734\tvalidation_1-logloss:0.46815\n",
      "[4]\tvalidation_0-logloss:0.34224\tvalidation_1-logloss:0.43913\n",
      "[5]\tvalidation_0-logloss:0.30425\tvalidation_1-logloss:0.41570\n",
      "[6]\tvalidation_0-logloss:0.27178\tvalidation_1-logloss:0.38953\n",
      "[7]\tvalidation_0-logloss:0.24503\tvalidation_1-logloss:0.37317\n",
      "[8]\tvalidation_0-logloss:0.22050\tvalidation_1-logloss:0.35628\n",
      "[9]\tvalidation_0-logloss:0.19873\tvalidation_1-logloss:0.33798\n",
      "[10]\tvalidation_0-logloss:0.17945\tvalidation_1-logloss:0.32463\n",
      "[11]\tvalidation_0-logloss:0.16354\tvalidation_1-logloss:0.31384\n",
      "[12]\tvalidation_0-logloss:0.15032\tvalidation_1-logloss:0.30607\n",
      "[13]\tvalidation_0-logloss:0.13813\tvalidation_1-logloss:0.30143\n",
      "[14]\tvalidation_0-logloss:0.12798\tvalidation_1-logloss:0.29513\n",
      "[15]\tvalidation_0-logloss:0.11926\tvalidation_1-logloss:0.28891\n",
      "[16]\tvalidation_0-logloss:0.11111\tvalidation_1-logloss:0.28290\n",
      "[17]\tvalidation_0-logloss:0.10351\tvalidation_1-logloss:0.27835\n",
      "[18]\tvalidation_0-logloss:0.09474\tvalidation_1-logloss:0.27295\n",
      "[19]\tvalidation_0-logloss:0.08922\tvalidation_1-logloss:0.27215\n",
      "[20]\tvalidation_0-logloss:0.08406\tvalidation_1-logloss:0.27168\n",
      "[21]\tvalidation_0-logloss:0.07892\tvalidation_1-logloss:0.27093\n",
      "[22]\tvalidation_0-logloss:0.07355\tvalidation_1-logloss:0.26561\n",
      "[23]\tvalidation_0-logloss:0.06976\tvalidation_1-logloss:0.26670\n",
      "[24]\tvalidation_0-logloss:0.06569\tvalidation_1-logloss:0.26871\n",
      "[25]\tvalidation_0-logloss:0.06220\tvalidation_1-logloss:0.26484\n",
      "[26]\tvalidation_0-logloss:0.05946\tvalidation_1-logloss:0.26604\n",
      "[27]\tvalidation_0-logloss:0.05688\tvalidation_1-logloss:0.26836\n",
      "[28]\tvalidation_0-logloss:0.05457\tvalidation_1-logloss:0.26746\n",
      "[29]\tvalidation_0-logloss:0.05161\tvalidation_1-logloss:0.26410\n",
      "[30]\tvalidation_0-logloss:0.04900\tvalidation_1-logloss:0.26314\n",
      "[31]\tvalidation_0-logloss:0.04658\tvalidation_1-logloss:0.26210\n",
      "[32]\tvalidation_0-logloss:0.04442\tvalidation_1-logloss:0.25918\n",
      "[33]\tvalidation_0-logloss:0.04293\tvalidation_1-logloss:0.25575\n",
      "[34]\tvalidation_0-logloss:0.04149\tvalidation_1-logloss:0.25681\n",
      "[35]\tvalidation_0-logloss:0.03991\tvalidation_1-logloss:0.25727\n",
      "[36]\tvalidation_0-logloss:0.03849\tvalidation_1-logloss:0.25710\n",
      "[37]\tvalidation_0-logloss:0.03702\tvalidation_1-logloss:0.25274\n",
      "[38]\tvalidation_0-logloss:0.03552\tvalidation_1-logloss:0.25427\n",
      "[39]\tvalidation_0-logloss:0.03441\tvalidation_1-logloss:0.25366\n",
      "[40]\tvalidation_0-logloss:0.03335\tvalidation_1-logloss:0.25410\n",
      "[41]\tvalidation_0-logloss:0.03259\tvalidation_1-logloss:0.25415\n",
      "[42]\tvalidation_0-logloss:0.03172\tvalidation_1-logloss:0.25421\n",
      "[43]\tvalidation_0-logloss:0.03110\tvalidation_1-logloss:0.25265\n",
      "[44]\tvalidation_0-logloss:0.03025\tvalidation_1-logloss:0.24974\n",
      "[45]\tvalidation_0-logloss:0.02961\tvalidation_1-logloss:0.25033\n",
      "[46]\tvalidation_0-logloss:0.02904\tvalidation_1-logloss:0.24858\n",
      "[47]\tvalidation_0-logloss:0.02849\tvalidation_1-logloss:0.25082\n",
      "[48]\tvalidation_0-logloss:0.02802\tvalidation_1-logloss:0.24968\n",
      "[49]\tvalidation_0-logloss:0.02741\tvalidation_1-logloss:0.24913\n",
      "[50]\tvalidation_0-logloss:0.02689\tvalidation_1-logloss:0.24924\n",
      "[51]\tvalidation_0-logloss:0.02644\tvalidation_1-logloss:0.24483\n",
      "[52]\tvalidation_0-logloss:0.02593\tvalidation_1-logloss:0.24508\n",
      "[53]\tvalidation_0-logloss:0.02534\tvalidation_1-logloss:0.24153\n",
      "[54]\tvalidation_0-logloss:0.02500\tvalidation_1-logloss:0.23781\n",
      "[55]\tvalidation_0-logloss:0.02458\tvalidation_1-logloss:0.23909\n",
      "[56]\tvalidation_0-logloss:0.02422\tvalidation_1-logloss:0.23809\n",
      "[57]\tvalidation_0-logloss:0.02380\tvalidation_1-logloss:0.23843\n",
      "[58]\tvalidation_0-logloss:0.02347\tvalidation_1-logloss:0.23802\n",
      "[59]\tvalidation_0-logloss:0.02310\tvalidation_1-logloss:0.23837\n",
      "[60]\tvalidation_0-logloss:0.02275\tvalidation_1-logloss:0.23923\n",
      "[61]\tvalidation_0-logloss:0.02257\tvalidation_1-logloss:0.23813\n",
      "[62]\tvalidation_0-logloss:0.02242\tvalidation_1-logloss:0.23983\n",
      "[63]\tvalidation_0-logloss:0.02227\tvalidation_1-logloss:0.23883\n",
      "[64]\tvalidation_0-logloss:0.02186\tvalidation_1-logloss:0.23589\n",
      "[65]\tvalidation_0-logloss:0.02162\tvalidation_1-logloss:0.23630\n",
      "[66]\tvalidation_0-logloss:0.02149\tvalidation_1-logloss:0.23795\n",
      "[67]\tvalidation_0-logloss:0.02136\tvalidation_1-logloss:0.23704\n",
      "[68]\tvalidation_0-logloss:0.02123\tvalidation_1-logloss:0.23670\n",
      "[69]\tvalidation_0-logloss:0.02097\tvalidation_1-logloss:0.23745\n",
      "[70]\tvalidation_0-logloss:0.02087\tvalidation_1-logloss:0.23739\n",
      "[71]\tvalidation_0-logloss:0.02073\tvalidation_1-logloss:0.23908\n",
      "[72]\tvalidation_0-logloss:0.02062\tvalidation_1-logloss:0.24064\n",
      "[73]\tvalidation_0-logloss:0.02050\tvalidation_1-logloss:0.23973\n",
      "[74]\tvalidation_0-logloss:0.02039\tvalidation_1-logloss:0.23972\n",
      "[75]\tvalidation_0-logloss:0.02029\tvalidation_1-logloss:0.23927\n",
      "[76]\tvalidation_0-logloss:0.02019\tvalidation_1-logloss:0.24081\n",
      "[77]\tvalidation_0-logloss:0.02008\tvalidation_1-logloss:0.24054\n",
      "[78]\tvalidation_0-logloss:0.01999\tvalidation_1-logloss:0.23844\n",
      "[79]\tvalidation_0-logloss:0.01989\tvalidation_1-logloss:0.23762\n",
      "[80]\tvalidation_0-logloss:0.01979\tvalidation_1-logloss:0.23914\n",
      "[81]\tvalidation_0-logloss:0.01969\tvalidation_1-logloss:0.23907\n",
      "[82]\tvalidation_0-logloss:0.01960\tvalidation_1-logloss:0.23830\n",
      "[83]\tvalidation_0-logloss:0.01952\tvalidation_1-logloss:0.23866\n",
      "[84]\tvalidation_0-logloss:0.01943\tvalidation_1-logloss:0.23841\n",
      "[85]\tvalidation_0-logloss:0.01933\tvalidation_1-logloss:0.23992\n",
      "[86]\tvalidation_0-logloss:0.01925\tvalidation_1-logloss:0.23917\n",
      "[87]\tvalidation_0-logloss:0.01916\tvalidation_1-logloss:0.24061\n",
      "[88]\tvalidation_0-logloss:0.01908\tvalidation_1-logloss:0.23862\n",
      "[89]\tvalidation_0-logloss:0.01900\tvalidation_1-logloss:0.23858\n",
      "[90]\tvalidation_0-logloss:0.01892\tvalidation_1-logloss:0.23843\n",
      "[91]\tvalidation_0-logloss:0.01884\tvalidation_1-logloss:0.23837\n",
      "[92]\tvalidation_0-logloss:0.01876\tvalidation_1-logloss:0.23978\n",
      "[93]\tvalidation_0-logloss:0.01868\tvalidation_1-logloss:0.23787\n",
      "[94]\tvalidation_0-logloss:0.01860\tvalidation_1-logloss:0.23862\n",
      "[95]\tvalidation_0-logloss:0.01853\tvalidation_1-logloss:0.23770\n",
      "[96]\tvalidation_0-logloss:0.01845\tvalidation_1-logloss:0.23767\n",
      "[97]\tvalidation_0-logloss:0.01838\tvalidation_1-logloss:0.23840\n",
      "[98]\tvalidation_0-logloss:0.01831\tvalidation_1-logloss:0.23817\n",
      "[99]\tvalidation_0-logloss:0.01824\tvalidation_1-logloss:0.23950\n",
      "[100]\tvalidation_0-logloss:0.01817\tvalidation_1-logloss:0.23945\n",
      "[101]\tvalidation_0-logloss:0.01809\tvalidation_1-logloss:0.23848\n",
      "[102]\tvalidation_0-logloss:0.01802\tvalidation_1-logloss:0.23668\n",
      "[103]\tvalidation_0-logloss:0.01795\tvalidation_1-logloss:0.23704\n",
      "[104]\tvalidation_0-logloss:0.01789\tvalidation_1-logloss:0.23536\n",
      "[105]\tvalidation_0-logloss:0.01781\tvalidation_1-logloss:0.23465\n",
      "[106]\tvalidation_0-logloss:0.01774\tvalidation_1-logloss:0.23536\n",
      "[107]\tvalidation_0-logloss:0.01768\tvalidation_1-logloss:0.23514\n",
      "[108]\tvalidation_0-logloss:0.01762\tvalidation_1-logloss:0.23447\n",
      "[109]\tvalidation_0-logloss:0.01756\tvalidation_1-logloss:0.23281\n",
      "[110]\tvalidation_0-logloss:0.01749\tvalidation_1-logloss:0.23447\n",
      "[111]\tvalidation_0-logloss:0.01743\tvalidation_1-logloss:0.23443\n",
      "[112]\tvalidation_0-logloss:0.01737\tvalidation_1-logloss:0.23512\n",
      "[113]\tvalidation_0-logloss:0.01731\tvalidation_1-logloss:0.23465\n",
      "[114]\tvalidation_0-logloss:0.01725\tvalidation_1-logloss:0.23379\n",
      "[115]\tvalidation_0-logloss:0.01719\tvalidation_1-logloss:0.23446\n",
      "[116]\tvalidation_0-logloss:0.01714\tvalidation_1-logloss:0.23443\n",
      "[117]\tvalidation_0-logloss:0.01708\tvalidation_1-logloss:0.23360\n",
      "[118]\tvalidation_0-logloss:0.01702\tvalidation_1-logloss:0.23195\n",
      "[119]\tvalidation_0-logloss:0.01696\tvalidation_1-logloss:0.23262\n",
      "[120]\tvalidation_0-logloss:0.01691\tvalidation_1-logloss:0.23104\n",
      "[121]\tvalidation_0-logloss:0.01685\tvalidation_1-logloss:0.23145\n",
      "[122]\tvalidation_0-logloss:0.01680\tvalidation_1-logloss:0.23143\n",
      "[123]\tvalidation_0-logloss:0.01675\tvalidation_1-logloss:0.23131\n",
      "[124]\tvalidation_0-logloss:0.01670\tvalidation_1-logloss:0.23119\n",
      "[125]\tvalidation_0-logloss:0.01664\tvalidation_1-logloss:0.22965\n",
      "[126]\tvalidation_0-logloss:0.01659\tvalidation_1-logloss:0.23120\n",
      "[127]\tvalidation_0-logloss:0.01654\tvalidation_1-logloss:0.23119\n",
      "[128]\tvalidation_0-logloss:0.01649\tvalidation_1-logloss:0.23110\n",
      "[129]\tvalidation_0-logloss:0.01644\tvalidation_1-logloss:0.22957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130]\tvalidation_0-logloss:0.01639\tvalidation_1-logloss:0.22934\n",
      "[131]\tvalidation_0-logloss:0.01634\tvalidation_1-logloss:0.22987\n",
      "[132]\tvalidation_0-logloss:0.01629\tvalidation_1-logloss:0.22927\n",
      "[133]\tvalidation_0-logloss:0.01624\tvalidation_1-logloss:0.23076\n",
      "[134]\tvalidation_0-logloss:0.01620\tvalidation_1-logloss:0.23030\n",
      "[135]\tvalidation_0-logloss:0.01615\tvalidation_1-logloss:0.22891\n",
      "[136]\tvalidation_0-logloss:0.01610\tvalidation_1-logloss:0.22883\n",
      "[137]\tvalidation_0-logloss:0.01606\tvalidation_1-logloss:0.22882\n",
      "[138]\tvalidation_0-logloss:0.01602\tvalidation_1-logloss:0.22876\n",
      "[139]\tvalidation_0-logloss:0.01597\tvalidation_1-logloss:0.22734\n",
      "[140]\tvalidation_0-logloss:0.01592\tvalidation_1-logloss:0.22881\n",
      "[141]\tvalidation_0-logloss:0.01588\tvalidation_1-logloss:0.22935\n",
      "[142]\tvalidation_0-logloss:0.01583\tvalidation_1-logloss:0.22880\n",
      "[143]\tvalidation_0-logloss:0.01579\tvalidation_1-logloss:0.22856\n",
      "[144]\tvalidation_0-logloss:0.01575\tvalidation_1-logloss:0.22725\n",
      "[145]\tvalidation_0-logloss:0.01571\tvalidation_1-logloss:0.22739\n",
      "[146]\tvalidation_0-logloss:0.01567\tvalidation_1-logloss:0.22724\n",
      "[147]\tvalidation_0-logloss:0.01562\tvalidation_1-logloss:0.22777\n",
      "[148]\tvalidation_0-logloss:0.01558\tvalidation_1-logloss:0.22726\n",
      "[149]\tvalidation_0-logloss:0.01555\tvalidation_1-logloss:0.22721\n",
      "[150]\tvalidation_0-logloss:0.01551\tvalidation_1-logloss:0.22697\n",
      "[151]\tvalidation_0-logloss:0.01546\tvalidation_1-logloss:0.22645\n",
      "[152]\tvalidation_0-logloss:0.01543\tvalidation_1-logloss:0.22782\n",
      "[153]\tvalidation_0-logloss:0.01539\tvalidation_1-logloss:0.22790\n",
      "[154]\tvalidation_0-logloss:0.01535\tvalidation_1-logloss:0.22665\n",
      "[155]\tvalidation_0-logloss:0.01531\tvalidation_1-logloss:0.22680\n",
      "[156]\tvalidation_0-logloss:0.01528\tvalidation_1-logloss:0.22732\n",
      "[157]\tvalidation_0-logloss:0.01524\tvalidation_1-logloss:0.22709\n",
      "[158]\tvalidation_0-logloss:0.01520\tvalidation_1-logloss:0.22659\n",
      "[159]\tvalidation_0-logloss:0.01516\tvalidation_1-logloss:0.22616\n",
      "[160]\tvalidation_0-logloss:0.01513\tvalidation_1-logloss:0.22631\n",
      "[161]\tvalidation_0-logloss:0.01509\tvalidation_1-logloss:0.22510\n",
      "[162]\tvalidation_0-logloss:0.01506\tvalidation_1-logloss:0.22562\n",
      "[163]\tvalidation_0-logloss:0.01502\tvalidation_1-logloss:0.22539\n",
      "[164]\tvalidation_0-logloss:0.01499\tvalidation_1-logloss:0.22671\n",
      "[165]\tvalidation_0-logloss:0.01495\tvalidation_1-logloss:0.22625\n",
      "[166]\tvalidation_0-logloss:0.01492\tvalidation_1-logloss:0.22585\n",
      "[167]\tvalidation_0-logloss:0.01489\tvalidation_1-logloss:0.22583\n",
      "[168]\tvalidation_0-logloss:0.01485\tvalidation_1-logloss:0.22562\n",
      "[169]\tvalidation_0-logloss:0.01482\tvalidation_1-logloss:0.22520\n",
      "[170]\tvalidation_0-logloss:0.01479\tvalidation_1-logloss:0.22570\n",
      "[171]\tvalidation_0-logloss:0.01476\tvalidation_1-logloss:0.22587\n",
      "[172]\tvalidation_0-logloss:0.01472\tvalidation_1-logloss:0.22466\n",
      "[173]\tvalidation_0-logloss:0.01469\tvalidation_1-logloss:0.22592\n",
      "[174]\tvalidation_0-logloss:0.01466\tvalidation_1-logloss:0.22599\n",
      "[175]\tvalidation_0-logloss:0.01463\tvalidation_1-logloss:0.22556\n",
      "[176]\tvalidation_0-logloss:0.01460\tvalidation_1-logloss:0.22535\n",
      "[177]\tvalidation_0-logloss:0.01457\tvalidation_1-logloss:0.22655\n",
      "[178]\tvalidation_0-logloss:0.01454\tvalidation_1-logloss:0.22674\n",
      "[179]\tvalidation_0-logloss:0.01451\tvalidation_1-logloss:0.22565\n",
      "[180]\tvalidation_0-logloss:0.01448\tvalidation_1-logloss:0.22565\n",
      "[181]\tvalidation_0-logloss:0.01445\tvalidation_1-logloss:0.22526\n",
      "[182]\tvalidation_0-logloss:0.01442\tvalidation_1-logloss:0.22545\n",
      "[183]\tvalidation_0-logloss:0.01439\tvalidation_1-logloss:0.22504\n",
      "[184]\tvalidation_0-logloss:0.01436\tvalidation_1-logloss:0.22554\n",
      "[185]\tvalidation_0-logloss:0.01433\tvalidation_1-logloss:0.22533\n",
      "[186]\tvalidation_0-logloss:0.01431\tvalidation_1-logloss:0.22426\n",
      "[187]\tvalidation_0-logloss:0.01428\tvalidation_1-logloss:0.22545\n",
      "[188]\tvalidation_0-logloss:0.01425\tvalidation_1-logloss:0.22563\n",
      "[189]\tvalidation_0-logloss:0.01422\tvalidation_1-logloss:0.22525\n",
      "[190]\tvalidation_0-logloss:0.01419\tvalidation_1-logloss:0.22504\n",
      "[191]\tvalidation_0-logloss:0.01417\tvalidation_1-logloss:0.22523\n",
      "[192]\tvalidation_0-logloss:0.01414\tvalidation_1-logloss:0.22529\n",
      "[193]\tvalidation_0-logloss:0.01411\tvalidation_1-logloss:0.22492\n",
      "[194]\tvalidation_0-logloss:0.01409\tvalidation_1-logloss:0.22472\n",
      "[195]\tvalidation_0-logloss:0.01406\tvalidation_1-logloss:0.22589\n",
      "[196]\tvalidation_0-logloss:0.01403\tvalidation_1-logloss:0.22595\n",
      "[197]\tvalidation_0-logloss:0.01401\tvalidation_1-logloss:0.22646\n",
      "[198]\tvalidation_0-logloss:0.01399\tvalidation_1-logloss:0.22665\n",
      "[199]\tvalidation_0-logloss:0.01396\tvalidation_1-logloss:0.22628\n",
      "[200]\tvalidation_0-logloss:0.01393\tvalidation_1-logloss:0.22609\n",
      "[201]\tvalidation_0-logloss:0.01391\tvalidation_1-logloss:0.22572\n",
      "[202]\tvalidation_0-logloss:0.01388\tvalidation_1-logloss:0.22536\n",
      "[203]\tvalidation_0-logloss:0.01386\tvalidation_1-logloss:0.22586\n",
      "[204]\tvalidation_0-logloss:0.01384\tvalidation_1-logloss:0.22568\n",
      "[205]\tvalidation_0-logloss:0.01381\tvalidation_1-logloss:0.22678\n",
      "[206]\tvalidation_0-logloss:0.01379\tvalidation_1-logloss:0.22642\n",
      "[207]\tvalidation_0-logloss:0.01377\tvalidation_1-logloss:0.22690\n",
      "[208]\tvalidation_0-logloss:0.01375\tvalidation_1-logloss:0.22710\n",
      "[209]\tvalidation_0-logloss:0.01373\tvalidation_1-logloss:0.22676\n",
      "[210]\tvalidation_0-logloss:0.01371\tvalidation_1-logloss:0.22643\n",
      "[211]\tvalidation_0-logloss:0.01368\tvalidation_1-logloss:0.22624\n",
      "[212]\tvalidation_0-logloss:0.01366\tvalidation_1-logloss:0.22727\n",
      "[213]\tvalidation_0-logloss:0.01364\tvalidation_1-logloss:0.22693\n",
      "[214]\tvalidation_0-logloss:0.01362\tvalidation_1-logloss:0.22675\n",
      "[215]\tvalidation_0-logloss:0.01360\tvalidation_1-logloss:0.22644\n",
      "[216]\tvalidation_0-logloss:0.01357\tvalidation_1-logloss:0.22665\n",
      "[217]\tvalidation_0-logloss:0.01355\tvalidation_1-logloss:0.22685\n",
      "[218]\tvalidation_0-logloss:0.01353\tvalidation_1-logloss:0.22653\n",
      "[219]\tvalidation_0-logloss:0.01351\tvalidation_1-logloss:0.22622\n",
      "[220]\tvalidation_0-logloss:0.01350\tvalidation_1-logloss:0.22642\n",
      "[221]\tvalidation_0-logloss:0.01348\tvalidation_1-logloss:0.22612\n",
      "[222]\tvalidation_0-logloss:0.01346\tvalidation_1-logloss:0.22594\n",
      "[223]\tvalidation_0-logloss:0.01344\tvalidation_1-logloss:0.22641\n",
      "[224]\tvalidation_0-logloss:0.01342\tvalidation_1-logloss:0.22623\n",
      "[225]\tvalidation_0-logloss:0.01340\tvalidation_1-logloss:0.22668\n",
      "[226]\tvalidation_0-logloss:0.01338\tvalidation_1-logloss:0.22766\n",
      "[227]\tvalidation_0-logloss:0.01336\tvalidation_1-logloss:0.22736\n",
      "[228]\tvalidation_0-logloss:0.01334\tvalidation_1-logloss:0.22706\n",
      "[229]\tvalidation_0-logloss:0.01333\tvalidation_1-logloss:0.22727\n",
      "[230]\tvalidation_0-logloss:0.01331\tvalidation_1-logloss:0.22709\n",
      "[231]\tvalidation_0-logloss:0.01329\tvalidation_1-logloss:0.22694\n",
      "[232]\tvalidation_0-logloss:0.01327\tvalidation_1-logloss:0.22706\n",
      "[233]\tvalidation_0-logloss:0.01325\tvalidation_1-logloss:0.22676\n",
      "[234]\tvalidation_0-logloss:0.01324\tvalidation_1-logloss:0.22773\n",
      "[235]\tvalidation_0-logloss:0.01322\tvalidation_1-logloss:0.22743\n",
      "오차 행렬\n",
      "[[35  2]\n",
      " [ 2 75]]\n",
      "정확도: 0.9649, 정밀도: 0.9740, 재현율: 0.9740,    F1: 0.9740, AUC:0.9944\n"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators=400,\n",
    "                            learning_rate=round(best['learning_rate'], 5),\n",
    "                            max_depth=int(best['max_depth']),\n",
    "                            min_child_weight=int(best['min_child_weight']),\n",
    "                            colsample_bytree=round(best['colsample_bytree'], 5)\n",
    "                           )\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "xgb_wrapper.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='logloss',\n",
    "                eval_set=evals, verbose=True)\n",
    "\n",
    "preds = xgb_wrapper.predict(X_test)\n",
    "pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266bb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
