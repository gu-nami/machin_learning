{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 텍스트 분석\n",
    "## 08 문서 유사도\n",
    "### 문서 유사도 측정 방법- 코사인 유사도\n",
    "\n",
    "문서와 문서 간의 유사도 비교는 일반적으로 코사인 유사도(Cosine Similarity)를 사용한다. 코사인 유사도는 두 벡터 사이의 사잇각을 구해서 얼마나 유사한지 수치로 적용한 것이다.\n",
    "\n",
    "### 두 벡터 사잇각\n",
    "\n",
    "두 벡터의 사잇각에 따라서 상호 관계는 다음과 같이 유사하거나 관련이 없거나 아예 반대관계가 될수 있다.\n",
    "\n",
    "![](https://velog.velcdn.com/images%2Fgjtang%2Fpost%2F966152b6-1be7-4ef5-b217-fb353f15227b%2Fimage.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코사인 유사도는 아래의 식으로 구할 수 있다.\n",
    "\n",
    "$similarity = cos\\theta = \\frac{A•B}{||A||||B||} = \\frac{\\sum_{i=1}^n A_iB_i}{\\sqrt{\\sum_{i=1}^n A_i^2}\\sqrt{\\sum_{i=1}^n B_i^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__코사인 유사도가 문서의 유사도 비교에 가장 많이 사용되는 이유__\n",
    "\n",
    "문서를 피처 벡터화 변환하면 차원이 매우 많은 희소 행렬이 되기 쉽습니다. 이러한 희소 행렬 기반에서 문서와 문서 벡터 간의 크기에 기반한 유사도 지표는 정확도가 떨어지기 쉽다. 또한 문서가 매우 긴 경우 단어의 빈도수도 더 많을 것이기 때문에 이러한 빈도수에만 기반해서는 공정한 비교를 할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "간단한 문서에 대해서 서로 간의 문서 유사도를 코사인 유사도 기반으로 구해 본다. 먼저 두개의 넘파이 배열에 대한 코사인 유사도를 구하는 cos_similarity()함수를 작성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cos_similarity(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    l2_norm = (np.sqrt(sum(np.square(v1))) * np.sqrt(sum(np.square(v2))))\n",
    "    similarity = dot_product / l2_norm     \n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc_list로 정의된 3개의 간단한 문서의 유사도를 비교하기 위해 이 문서를 TF-IDF로 벡터화된 행렬로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "doc_list = ['if you take the blue pill, the story ends' ,\n",
    "            'if you take the red pill, you stay in Wonderland',\n",
    "            'if you take the red pill, I show you how deep the rabbit hole goes']\n",
    "\n",
    "tfidf_vect_simple = TfidfVectorizer()\n",
    "feature_vect_simple = tfidf_vect_simple.fit_transform(doc_list)\n",
    "print(feature_vect_simple.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cos_similarity() 함수를 이용해 두개 문서의 유사도를 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFidfVectorizer로 transform()한 결과는 Sparse Matrix이므로 Dense Matrix로 변환. \n",
    "feature_vect_dense = feature_vect_simple.todense()\n",
    "\n",
    "#첫번째 문장과 두번째 문장의 feature vector  추출\n",
    "# feature_vect_dense[0] : doc_list 첫 번재 문서의 피처 벡터화\n",
    "# feature_vect_dense[1] : doc_list 두 번째 문서의 피처 벡터화\n",
    "vect1 = np.array(feature_vect_dense[0]).reshape(-1,)\n",
    "vect2 = np.array(feature_vect_dense[1]).reshape(-1,)\n",
    "\n",
    "#첫번째 문장과 두번째 문장의 feature vector로 두개 문장의 Cosine 유사도 추출\n",
    "similarity_simple = cos_similarity(vect1, vect2 )\n",
    "print('문장 1, 문장 2 Cosine 유사도: {0:.3f}'.format(similarity_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 문장과 세 번째 문장 그리고 두 번째 문장과 세 번째 문장의 유사도도 측정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect1 = np.array(feature_vect_dense[0]).reshape(-1,)\n",
    "vect3 = np.array(feature_vect_dense[2]).reshape(-1,)\n",
    "similarity_simple = cos_similarity(vect1, vect3 )\n",
    "print('문장 1, 문장 3 Cosine 유사도: {0:.3f}'.format(similarity_simple))\n",
    "\n",
    "vect2 = np.array(feature_vect_dense[1]).reshape(-1,)\n",
    "vect3 = np.array(feature_vect_dense[2]).reshape(-1,)\n",
    "similarity_simple = cos_similarity(vect2, vect3 )\n",
    "print('문장 2, 문장 3 Cosine 유사도: {0:.3f}'.format(similarity_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런은 코사인 유사도를 측정하기 위해 sklearn.metrics.pairwise.cosine_similarity() 함수는 두 개의 입력 파라미터를 받는다.\n",
    "\n",
    "+ 첫 번째 파라미터는 비교 기준이 되는 문서의 피처 행렬\n",
    "+ 두 번째 파라미터는 비교되는 문서의 피처행렬이다.\n",
    "\n",
    "첫 번째 문서와 비교해 바로 자신 문서인 첫 번째 문서, 그리고 두 번째, 세 번재 문서의 유사도를 측정해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_simple_pair = cosine_similarity(feature_vect_simple[0] , feature_vect_simple)\n",
    "print(similarity_simple_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 번째 유사도 값인 0.40207758은 첫 번재 문서와 두 번째 문서의 유사도, 0.40425045는 첫 번째와 세 번째 문서의 유사도 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞의 1값 제외하고 출력\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_simple_pair = cosine_similarity(feature_vect_simple[0] , feature_vect_simple[1:])\n",
    "print(similarity_simple_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 개별 문서에 쌍으로 코사인 유사도 값을 계산해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_simple_pair = cosine_similarity(feature_vect_simple , feature_vect_simple)\n",
    "print(similarity_simple_pair)\n",
    "print('shape:',similarity_simple_pair.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 로우는 1번 문서와 2, 3번째 문서의 코사인 유사도, 두 번째 로우는 2번 문서와 1, 3번째 문서의 코사인 유사도, 세 번째 로우는 3번 문서와 1,2번째 문서의 코사인 유사도를 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opnion Review 데이터 세트를 이용한 문서 유사도 측정\n",
    "\n",
    "Opinion Review 데이터 세트를 이용해 이들 문서 간의 유사도를 측정해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "lemmar = WordNetLemmatizer()\n",
    "\n",
    "# 입력으로 들어온 token단어들에 대해서 lemmatization 어근 변환. \n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "# TfidfVectorizer 객체 생성 시 tokenizer인자로 해당 함수를 설정하여 lemmatization 적용\n",
    "# 입력으로 문장을 받아서 stop words 제거-> 소문자 변환 -> 단어 토큰화 -> lemmatization 어근 변환. \n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = './OpinosisDataset1.0/OpinosisDataset1.0/topics'\n",
    "all_files = glob.glob(os.path.join(path, \"*.data\"))     \n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "for file_ in all_files:\n",
    "    df = pd.read_table(file_,index_col=None, header=0,encoding='latin1')\n",
    "    filename_ = file_.split('\\\\')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english' , \\\n",
    "                             ngram_range=(1,2), min_df=0.05, max_df=0.85 )\n",
    "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])\n",
    "\n",
    "km_cluster = KMeans(n_clusters=3, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(feature_vect)\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_\n",
    "document_df['cluster_label'] = cluster_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "호텔을 주제로 군집화된 문서를 이용해 특정 문서와 다른 문서간의 유사도를 알아본다. 각 문서가 피처 벡터화된 데이터를 cosine_simularity()를 이용해 상호 비교해 유사도를 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "호텔을 주제로 군집화된 데이터를 먼저 추출하고 이 데이터에 해당하는 TfidVectorizer의 데이터를 추출한다. 호텔 군집화 데이터를 기반으로 별도의 TF-IDF 벡터화를 수행하지 않고 바로 위에서 TfidVectorizer로 만들어진 데이터에서 그대로 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame 객체 변수인 document_df에서 먼저 호텔로 군집화된 문서의 인덱스를 추출한다. 이렇게 추출된 인덱스를 그대로 이용해 TfidVectorizer 객체 변수인 feature_vect에서 호텔로 군집화된 문서의 피처 벡터를 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호텔로 클러스터링 된 문서들의 DataFrame Index: Int64Index([1, 13, 14, 15, 20, 21, 24, 28, 30, 31, 32, 38, 39, 40, 45, 46], dtype='int64')\n",
      "##### 비교 기준 문서명  bathroom_bestwestern_hotel_sfo  와 타 문서 유사도######\n",
      "[[1.         0.0430688  0.05221059 0.06189595 0.05846178 0.06193118\n",
      "  0.03638665 0.11742762 0.38038865 0.32619948 0.51442299 0.11282857\n",
      "  0.13989623 0.1386783  0.09518068 0.07049362]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# cluster_label=2인 데이터는 호텔로 클러스터링된 데이터임. DataFrame에서 해당 Index를 추출\n",
    "hotel_indexes = document_df[document_df['cluster_label']==2].index\n",
    "print('호텔로 클러스터링 된 문서들의 DataFrame Index:', hotel_indexes)\n",
    "\n",
    "# 호텔로 클러스터링된 데이터 중 첫번째 문서를 추출하여 파일명 표시.  \n",
    "comparison_docname = document_df.iloc[hotel_indexes[0]]['filename']\n",
    "print('##### 비교 기준 문서명 ',comparison_docname,' 와 타 문서 유사도######')\n",
    "\n",
    "''' document_df에서 추출한 Index 객체를 feature_vect로 입력하여 호텔 클러스터링된 feature_vect 추출 \n",
    "이를 이용하여 호텔로 클러스터링된 문서 중 첫번째 문서와 다른 문서간의 코사인 유사도 측정.'''\n",
    "similarity_pair = cosine_similarity(feature_vect[hotel_indexes[0]] , feature_vect[hotel_indexes])\n",
    "print(similarity_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 문서와 다른 문서 간에 유사도가 높은 순으로 이를 정렬하고 시각화해본다. cosine_similarity()는 쌍 형태의 ndarray를 반환하므로 이를 판다스 인덱스로 이용하기 위해 reshape(-1)로 차원을 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호텔로 클러스터링 된 문서들의 DataFrame Index: Int64Index([1, 13, 14, 15, 20, 21, 24, 28, 30, 31, 32, 38, 39, 40, 45, 46], dtype='int64')\n",
      "##### 비교 기준 문서명  bathroom_bestwestern_hotel_sfo  와 타 문서 유사도######\n",
      "[[1.         0.0430688  0.05221059 0.06189595 0.05846178 0.06193118\n",
      "  0.03638665 0.11742762 0.38038865 0.32619948 0.51442299 0.11282857\n",
      "  0.13989623 0.1386783  0.09518068 0.07049362]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# cluster_label=2인 데이터는 호텔로 클러스터링된 데이터임. DataFrame에서 해당 Index를 추출\n",
    "hotel_indexes = document_df[document_df['cluster_label']==2].index\n",
    "print('호텔로 클러스터링 된 문서들의 DataFrame Index:', hotel_indexes)\n",
    "\n",
    "# 호텔로 클러스터링된 데이터 중 첫번째 문서를 추출하여 파일명 표시.  \n",
    "comparison_docname = document_df.iloc[hotel_indexes[0]]['filename']\n",
    "print('##### 비교 기준 문서명 ',comparison_docname,' 와 타 문서 유사도######')\n",
    "\n",
    "''' document_df에서 추출한 Index 객체를 feature_vect로 입력하여 호텔 클러스터링된 feature_vect 추출 \n",
    "이를 이용하여 호텔로 클러스터링된 문서 중 첫번째 문서와 다른 문서간의 코사인 유사도 측정.'''\n",
    "similarity_pair = cosine_similarity(feature_vect[hotel_indexes[0]] , feature_vect[hotel_indexes])\n",
    "print(similarity_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 문서인 샌프란시스코의 베스트 웨스턴 호텔 화장실 리뷰와 가장 비슷한 문서는 room_holiday_inn_london이다. 약 0\n",
    "514의 코사인 유사도 값을 나타내고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
